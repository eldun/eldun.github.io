<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-04-27T22:11:59-04:00</updated><id>http://localhost:4000/feed.xml</id><entry><title type="html">Ray Tracing in One Weekend:</title><link href="http://localhost:4000/2023/04/25/rt-part-3.html" rel="alternate" type="text/html" title="Ray Tracing in One Weekend:" /><published>2023-04-25T22:52:17-04:00</published><updated>2023-04-25T22:52:17-04:00</updated><id>http://localhost:4000/2023/04/25/rt-part-3</id><content type="html" xml:base="http://localhost:4000/2023/04/25/rt-part-3.html"><![CDATA[<p><a id="continue-reading-point"></a></p>

<p><span class="note">
    I started this path tracer months ago, and only started this blog in late May. The version of Shirley’s book that I used is from some time in 2018 (Version 1.54), and I have found that there is a recently updated version (3.1.2) on <a href="https://raytracing.github.io/">his website</a> from June 6th, 2020! I also supplemented Shirley’s book with <a href="https://viclw17.github.io/writing.html">Victor Li’s posts on the subject</a>. As such, there may be differences in implementation compared to the most recent version of Ray Tracing in One Weekend. <br /><br />I am trying to keep things easy-to-follow, mostly sticking with my original code and only changing or adding what I deem to be necessary for readability, clarity, or image rendering purposes. If you are reading this to build your own ray tracer, I highly recommend Shirley’s book as a primary source.
</span></p>

<hr />
<h2 id="contents">Contents</h2>

<ul class="part-navigator">
    
    
    
    
    
    
    
    
    
    

    <li>
        <a href="/2020/05/20/ray-tracing-in-one-weekend-part-one.html#post-title" class="btn">Part One - An Introduction</a>

    </li>
    
    
    

    <li>
        <a href="/2020/06/19/ray-tracing-in-one-weekend-part-two.html#post-title" class="btn">Part Two - The First Weekend</a>

    </li>
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

    <li>
        <a href="/2023/04/25/rt-part-3.html#post-title" class="btn inactive">Part Three - The Next Weekend</a>

    </li>
    
    
</ul>

<hr />

<h2 id="motion-blur"><a id="motion-blur"></a>Motion Blur</h2>

<p>Similarly to how we simulated <a href="http://localhost:4000/2020/06/19/ray-tracing-in-one-weekend-part-two.html#depth-of-field">depth of field</a> and <a href="http://localhost:4000/2020/06/19/ray-tracing-in-one-weekend-part-two.html#fuzzy-metal">imperfect reflections</a> through brute force in my <a href="/2020/06/19/ray-tracing-in-one-weekend-part-two.html">previous ray tracing post</a>, we can also implement motion blur.</p>

<p>Motion blur (in a real, physical camera) is a the result of movement while the camera’s shutter is open. The image produced is the average of what the camera “saw” over that amount of time.</p>

<p><span class="captioned-image">
<img src="/assets/images/blog-images/path-tracer/the-next-week/shutter.webp" alt="shutter-speed" />
<a href="https://www.studiobinder.com/blog/what-is-shutter-speed/">(source)</a>
</span></p>

<h3 id="adapting-our-ray-class"><a id="adapting-our-ray-class"></a>Adapting our Ray Class</h3>

<p>First, we give our ray the ability to store the time at which it exists.</p>

<p><code class="language-plaintext highlighter-rouge">ray.h</code>:</p>

<pre><code class="language-diff-cpp diff-highlight"> 
 class Ray {
	public:
	ray() {}
+	ray(const vec3&amp; a, const vec3&amp; b, double moment) { A = a; B = b; mMoment = moment; }
	vec3 origin() const		{ return A; }
	vec3 direction() const	{ return B; }
+	double moment() const  	{ return mMoment; }
	vec3 point_at_parameter(double t) const { return A + t * B; }
 	
	vec3 A;
	vec3 B;
+	double mMoment;
 };</code></pre>

<h3 id="adapting-our-camera-class"><a id="adapting-our-camera-class"></a>Adapting our Camera Class</h3>

<p>Now we have to update the camera to give each ray a time upon “shooting” one:
<code class="language-plaintext highlighter-rouge">camera.h</code>:</p>

<pre><code class="language-diff-cpp diff-highlight">
class camera
	{
	public:
+		camera(vec3 lookFrom, vec3 lookAt, vec3 vUp, double vFov, double aspectRatio, double aperture, double focusDistance, double shutterOpenDuration)
		{
			lensRadius = aperture / 2;
			double theta = vFov * pi / 180;
			double halfHeight = tan(theta / 2);
			double halfWidth = aspectRatio * halfHeight;
			origin = lookFrom;
			w = unit_vector(lookFrom - lookAt);
			u = unit_vector(cross(vUp, w));
			v = cross(w, u);
			lowerLeftCorner = origin - halfWidth * focusDistance * u - halfHeight * focusDistance * v - focusDistance * w;
			horizontal = 2 * halfWidth * focusDistance * u;
			vertical = 2 * halfHeight * focusDistance * v;
+			this-&gt;shutterOpenDuration = shutterOpenDuration;
		}

		ray get_ray(double s, double t)
		{
			vec3 rd = lensRadius * random_unit_disk_coordinate();
			vec3 offset = u * rd.x() + v * rd.y();
			return ray(origin + offset,
					lowerLeftCorner + s * horizontal + t * vertical - origin - offset,
+					random_double(0, shutterOpenDuration));
		}

	private:
		vec3 origin;
		vec3 lowerLeftCorner;
		vec3 horizontal;
		vec3 vertical;
		vec3 u, v, w;
		double lensRadius;
+		double shutterOpenDuration;
	};
...
</code></pre>

<h3 id="creating-moving-spheres"><a id="creating-moving-spheres"></a>Creating Moving Spheres</h3>

<p>Motion blur would be useless without motion. We can modify our spheres to move linearly from some point <code class="language-plaintext highlighter-rouge">centerStart</code> to another <code class="language-plaintext highlighter-rouge">centerEnd</code> starting at <code class="language-plaintext highlighter-rouge">moveStartTime</code> and stopping at <code class="language-plaintext highlighter-rouge">moveEndTime</code>.</p>

<p><code class="language-plaintext highlighter-rouge">sphere.h</code>:</p>

<pre><code class="language-diff-cpp diff-highlight"> 
	class sphere : public hittable {
		public:
		sphere() {}
		sphere(vec3 center, float radius, material* material) : 
+			centerStart(center), 
+			centerEnd(center), 
+			moveStartTime(0),
+			moveEndTime(0),
			radius(radius), 
			material_ptr(material){};

+		// Moving sphere
+		sphere(vec3 centerStart, vec3 centerEnd, double timeToTravel, float radius, material &#42;material) : 
+			centerStart(centerStart),
+			centerEnd(centerEnd),
+			moveStartTime(moveStartTime), 
+			moveEndTime(moveEndTime),
+			radius(radius), 
+			material_ptr(material){};

		virtual bool hit(const ray &amp;r, double tmin, double tmax, hit_record &amp;rec) const;

+		vec3 centerAt(double time) const;

+		vec3 centerStart, centerEnd;
+		double moveStartTime, moveEndTime;
		double radius;
		material* material_ptr;
	};
	</code></pre>

<p>Checking for a hit remains mostly the same - we just account for moving spheres by calculating the centers at specific times. If you need a refresher on the implementation details of sphere collisions, check <a href="http://localhost:4000/2020/06/19/ray-tracing-in-one-weekend-part-two.html#simplifying-ray-sphere-intersection">here</a>. I stray from Shirley’s code a small amount here by actually checking if the sphere has moved yet, is moving, or has stopped moving. The result can look a little <a href="#wait-then-move-sphere">goofy</a>, but I like having the option for more interesting motion, and the code feels a bit less ambiguous than Shirley’s:</p>
<blockquote>
  <p>I’ll create a sphere class that has its center move linearly from center0 at time0 to center1 at time1. Outside that time interval it continues on, so those times need not match up with the camera aperture open and close.</p>
</blockquote>

<p><code class="language-plaintext highlighter-rouge">sphere.h</code>:</p>
<pre><code class="language-diff-cpp diff-highlight"> 

	bool sphere::hit(const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const
	{
+		vec3 oc = r.origin() - centerAt(r.moment()); // Vector from center to ray origin
		double a = r.direction().length_squared();
		double halfB = dot(oc, r.direction());
		double c = oc.length_squared() - radius * radius;
		double discriminant = (halfB * halfB) - (a * c);
		if (discriminant &gt; 0.0) {
			auto root = sqrt(discriminant);

			auto temp = (-halfB - root) / a;

			temp = (-halfB + root) / a;
			if (temp &lt; t_max &amp;&amp; temp &gt; t_min) {
				rec.t = temp;
				rec.p = r.point_at_parameter(rec.t);
+				vec3 outward_normal = (rec.p - centerAt(r.moment())) / radius;
				rec.set_face_normal(r, outward_normal);
				rec.material_ptr = material_ptr;
				return true;
			}
		}
		return false;
	}

+	vec3 sphere::centerAt(double time) const {
+
+		// Prevent divide by zero(naN) for static spheres
+		if (moveStartTime == moveEndTime) {
+			return centerStart;
+		}
+
+		else if (time &lt; moveStartTime){
+			return centerStart;
+		}
+
+		else if (time &gt; moveEndTime){
+			return centerEnd;
+		}
+
+		else 
+			return centerStart + ((time - moveStartTime) / (moveEndTime-moveStartTime)) * (centerEnd - centerStart);	
+	}
}

</code></pre>

<h3 id="adapting-our-material-class"><a id="adapting-our-material-class"></a>Adapting our Material Class</h3>

<p>All calls to our ray constructor within <code class="language-plaintext highlighter-rouge">material.h</code> must be updated as well:</p>

<pre><code class="language-diff-cpp diff-highlight"> 
class lambertian : public material {
    public:
        lambertian(const vec3&amp; a) : albedo(a){};
        virtual bool scatter(const ray&amp; ray_in, 
                            const hit_record&amp; rec, 
                            vec3&amp; attenuation, 
                            ray&amp; scattered) const {
            vec3 scatter_direction = rec.p + rec.normal + random_unit_vector();
+            scattered = ray(rec.p, scatter_direction - rec.p, ray_in.moment());
            attenuation = albedo;
            return true;
        }
    vec3 albedo; // reflectivity
 };

 // Simulate reflection of a metal (see MetalReflectivity.png)
 // See FuzzyReflections.png for a visualization of fuzziness.
 class metal : public material {
    public:
        metal(const vec3&amp; a, double f) : albedo(a) {
            if (f&lt;1) fuzz = f; else fuzz = 1; // max fuzz of 1, for now.
        }
        virtual bool scatter(const ray&amp; ray_in, 
                            const hit_record&amp; rec, 
                            vec3&amp; attenuation, 
                            ray&amp; scattered) const {
        vec3 reflected = reflect(unit_vector(ray_in.direction()), rec.normal);
+        scattered = ray(rec.p, reflected + fuzz * random_unit_sphere_coordinate(), ray_in.moment()); // large spheres or grazing rays may go below the surface. In that case, they'll just be absorbed.
        attenuation = albedo;
        return dot(scattered.direction(), rec.normal) &gt; 0.0;
    }

    vec3 albedo;
    double fuzz;
 };

class dielectric : public material {
    public:
        dielectric(vec3 a, double ri) : albedo(a), ref_idx(ri) {}

        virtual bool scatter(
            const ray&amp; ray_in, const hit_record&amp; rec, vec3&amp; attenuation, ray&amp; scattered
        ) const {

            attenuation = albedo;

            double n1_over_n2 = (rec.frontFace) ? (1.0 / ref_idx) : (ref_idx);

            vec3 unit_direction = unit_vector(ray_in.direction());
            
            double cosine = fmin(dot(-unit_direction, rec.normal), 1.0);
            double reflect_random = random_double(0,1);
            double reflect_probability;

            vec3 refracted;
            vec3 reflected;

            if (refract(unit_direction, rec.normal, n1_over_n2, refracted)) {
                reflect_probability = schlick(cosine, ref_idx);

                if (reflect_random &lt; reflect_probability) {
                    vec3 reflected = reflect(unit_direction, rec.normal);
+                    scattered = ray(rec.p, reflected, ray_in.moment());
                    return true;
                }
+                scattered = ray(rec.p, refracted, ray_in.moment());
                return true;
            }

            else {
                reflected = reflect(unit_direction, rec.normal);
+                scattered = ray(rec.p, reflected, ray_in.moment());
                return true;
            }

            
        
        }
    public:
        double ref_idx;
        vec3 albedo;
};
</code></pre>

<h3 id="using-smart-pointers"><a id="using-smart-pointers"></a>Using Smart Pointers</h3>

<p>In the time since I’ve completed <a href="http://localhost:4000/2020/06/19/ray-tracing-in-one-weekend-part-two.html">The First Weekend</a>, Shirley has updated his code to use smart pointers in place of raw ones. I should’ve known to use smart pointers myself, but I was more familiar with java at that time and wanted to stick to the guide.</p>

<p>Anyway, you can read about smart pointers <a href="https://docs.microsoft.com/en-us/cpp/cpp/smart-pointers-modern-cpp">here</a>. We’ll mainly be using the <code class="language-plaintext highlighter-rouge">shared_ptr</code> class, which is designed for pointers that may have more than one owner. The raw pointer is not deleted until all <code class="language-plaintext highlighter-rouge">shared_ptr</code> owners have gone out of scope or given up ownership.</p>

<p><img src="/assets/images/blog-images/path-tracer/the-next-week/shared_ptr.png" alt="Shared pointer" /></p>

<p>Let’s start refactoring from the bottom up - <code class="language-plaintext highlighter-rouge">hittable.h</code>:</p>
<pre><code class="language-diff-cpp diff-highlight">
	#ifndef HITTABLEH
	#define HITTABLEH

	#include "ray.h"

+	#include &lt;memory&gt;
+	#include &lt;vector&gt;
+	
+	using std::shared_ptr;
+	using std::make_shared;

	class material; // forward declaration

	struct hit_record {
		double t; // parameter of the ray that locates the intersection point
		vec3 p; // intersection point
		vec3 normal;
		bool frontFace;
-		material&#42; material_ptr;
+		shared_ptr&lt;material&gt; material_ptr;

		inline void set_face_normal(const ray&amp; r, const vec3&amp; outward_normal) {
			frontFace = dot(r.direction(), outward_normal) &lt; 0;
			normal = frontFace ? outward_normal : -outward_normal;
		}
	};

	...

</code></pre>

<p>Additionally, we are going to edit <code class="language-plaintext highlighter-rouge">hittableList.h</code> to not only use shared pointers, but also use <a href="https://www.cplusplus.com/reference/vector/vector/">vectors</a>, which are basically arrays that can change size. Using raw dynamic arrays should generally be avoided, as they come with a heap of responsibility and potential for error, with no real benefits.</p>

<p><code class="language-plaintext highlighter-rouge">hittableList.h</code>:</p>
<pre><code class="language-diff-cpp diff-highlight">
#ifndef HITTABLELISTH
#define HITTABLELISTH

#include "hittable.h"

class hittable_list : public hittable {
public:
	hittable_list() {}
-	hittable_list(hittable&#42;&#42; l, int n) { list = l; list_size = n; }
+	hittable_list(shared_ptr&lt;hittable&gt; object) { add(object); }

+	void clear() { objects.clear(); }
+       void add(shared_ptr&lt;hittable&gt; object) { objects.push_back(object); }
	virtual bool hit(const ray&amp; r, double tmin, double tmax, hit_record&amp; rec) const;

-	hittable&#42;&#42; list;
-	int list_size;

+	std::vector&lt;shared_ptr&lt;hittable&gt;&gt; objects;

};

bool hittable_list::hit(const ray&amp; r, double t_min, double t_max, hit_record&amp; rec) const {
	hit_record temp_rec;
	bool hit_anything = false;
	double closest_so_far = t_max;
	for (const auto&amp; object : objects) {
-		for (int i = 0; i &lt; list_size; i++) {
-			if (list[i]-&gt;hit(r, t_min, closest_so_far, temp_rec)) {

+		if (object-&gt;hit(r, t_min, closest_so_far, temp_rec)) {
+			hit_anything = true;
			closest_so_far = temp_rec.t;
			rec = temp_rec;
		}
	}
	return hit_anything;
}

#endif // !HITTABLELISTH
</code></pre>

<p><code class="language-plaintext highlighter-rouge">sphere.h</code>:</p>

<pre><code class="language-diff-cpp diff-highlight">
class sphere : public hittable {
	public:
		sphere() {}
-		sphere(vec3 center, float radius, material &#42;material) : 
+		sphere(vec3 center, float radius, shared_ptr&lt;material&gt; material) : 
			centerStart(center), 
			centerEnd(center), 
			moveStartTime(0),
			moveEndTime(0),
			radius(radius), 
			material_ptr(material){};

		// Moving sphere
-			sphere(vec3 centerStart, vec3 centerEnd, double timeToTravel, float radius, material &#42;material) : 
+		sphere(vec3 centerStart, vec3 centerEnd, double timeToTravel, float radius, shared_ptr&lt;material&gt; material) : 
			centerStart(centerStart),
			centerEnd(centerEnd),
			moveStartTime(moveStartTime), 
			moveEndTime(moveEndTime),
			radius(radius), 
			material_ptr(material){};

		virtual bool hit(const ray &amp;r, double tmin, double tmax, hit_record &amp;rec) const;

		vec3 centerAt(double time) const;

		vec3 centerStart, centerEnd;
		double moveStartTime, moveEndTime;
		double radius;
-		material &#42;material_ptr;
+		shared_ptr&lt;material&gt; material_ptr;
	};

	...

</code></pre>

<p>The changes for <code class="language-plaintext highlighter-rouge">Main.cpp</code> mostly amount to replacing all uses of keyword <code class="language-plaintext highlighter-rouge">new</code> with <code class="language-plaintext highlighter-rouge">make_shared</code>.</p>

<p><code class="language-plaintext highlighter-rouge">Main.cpp</code>:</p>

<pre><code class="language-diff-cpp diff-highlight">
...
-	vec3 color(const ray&amp; r, hittable &#42;world, int depth) {
+	vec3 color(const ray&amp; r, hittable_list world, int depth) {
		hit_record rec;

		if (depth &lt;= 0) {
			return vec3(0,0,0);
		}  
-	    if (world-&gt;hit(r, 0.001, DBL_MAX, rec)) {
+		if (world.hit(r, 0.001, DBL_MAX, rec)) {
			ray scattered;
			...
	}


-	hittable &#42;random_scene() {
-    int n = 500;
-    hittable &#42;&#42; list = new hittable &#42; n+1];
-    list[0] =  new sphere(vec3(0,-1000,0), 1000, new lambertian(vec3(0.5, 0.5, 0.5))); //"Ground"
-    int i = 1;
-    for (int a = -11; a &lt; 11; a++) {
-        ...
-    }
-	 return new hittable_list(list,i);
-	}
-	


+	hittable_list random_scene() {
+		hittable_list world;
+		
+		auto ground_material = make_shared&lt;lambertian&gt;(vec3(0.5, 0.5, 0.5));
+		auto ground_sphere = make_shared&lt;sphere&gt;(vec3(0,-1000,0), 1000, ground_material);
+
+		world.add(ground_sphere);
+
+		...
+
+		return world;
+	}


int main() {

	int nx = 400; // Number of horizontal pixels
	int ny = 300; // Number of vertical pixels
	int ns = 30; // Number of samples for each pixel for anti-aliasing (see AntiAliasing.png for visualization)
    int maxDepth = 20; // Ray bounce limit
	std::cout &lt;&lt; "P3\n" &lt;&lt; nx &lt;&lt; " " &lt;&lt; ny &lt;&lt; "\n255\n"; // P3 signifies ASCII, 255 signifies max color value

	vec3 lookFrom(0, 2, 24);
	vec3 lookAt(0,1,0);
	double distToFocus = (lookFrom-lookAt).length();
	double aperture = 0.1; // bigger = blurrier

-	hittable &#42;world = random_scene();
+	auto world = random_scene();

	...

}
</code></pre>

<h3 id="setting-our-scene"><a id="setting-our-scene"></a>Setting our Scene</h3>
<p>Okay - we’ve got all the maintenence out of the way. Do whatever you please; I simplified the scene to show off our new feature with a black sphere moving from left to right:</p>

<div class="row">
<div class="captioned-image">
<img src="/assets/images/blog-images/path-tracer/the-next-week/blur-speed1-shutter1.png" alt="Moving sphere" />
Shutter speed 1, start move at 0, stop move at 1
</div>
<div class="captioned-image" id="wait-then-move-sphere">
<img src="/assets/images/blog-images/path-tracer/the-next-week/blur-start25end75-shutter1.png" alt="Wait then move sphere" />
Shutter speed 1, start move at .25, stop move at .75
</div>
</div>

<p><code class="language-plaintext highlighter-rouge">Main.cpp</code>:</p>
<pre><code class="language-diff-cpp diff-highlight">

hittable_list random_scene() {
    hittable_list world;
    
    auto ground_material = make_shared&lt;lambertian&gt;(vec3(0.5, 0.5, 0.5));
    auto ground_sphere = make_shared&lt;sphere&gt;(vec3(0,-1000,0), 1000, ground_material);

    world.add(ground_sphere);

-	...

    world.add(make_shared&lt;sphere&gt;(vec3(0, 1, 0), 1.0, make_shared&lt;dielectric&gt;(vec3(0.9,0.9,0.0), 1.5)));
    world.add(make_shared&lt;sphere&gt;(vec3(-4, 1, 0), 1.0, make_shared&lt;lambertian&gt;(vec3(0.4, 0.2, 0.1))));
    world.add(make_shared&lt;sphere&gt;(vec3(4, 1, 0), 1.0, make_shared&lt;metal&gt;(vec3(0.7, 0.6, 0.5), 0.0)));

+    // Moving sphere
+    world.add(make_shared&lt;sphere&gt;(vec3(-4, 3, 0), vec3(4,3,0), 0, 1.0, make_shared&lt;lambertian&gt;(vec3(0.0, 0.0, 0.0))));


    return world;
}

int main() {

	int nx = 1600; // Number of horizontal pixels
	int ny = 900; // Number of vertical pixels
	int ns = 60; // Number of samples for each pixel for anti-aliasing (see AntiAliasing.png for visualization)
    int maxDepth = 20; // Ray bounce limit
	std::cout &lt;&lt; "P3\n" &lt;&lt; nx &lt;&lt; " " &lt;&lt; ny &lt;&lt; "\n255\n"; // P3 signifies ASCII, 255 signifies max color value

	vec3 lookFrom(0, 2, 24);
	vec3 lookAt(0,1,0);
	double distToFocus = (lookFrom-lookAt).length();
	double aperture = 0.1; // bigger = blurrier

	auto world = random_scene();

+	camera cam(lookFrom, lookAt, vec3(0,1,0), 20,double(nx)/double(ny), aperture, distToFocus, 1.0);	

   	auto start = std::chrono::high_resolution_clock::now();


	for (int j = ny - 1; j &gt;= 0; j--) { // Navigate canvas
        std::cerr &lt;&lt; "\rScanlines remaining: " &lt;&lt; j &lt;&lt; ' ' &lt;&lt; std::flush;
		for (int i = 0; i &lt; nx; i++) {
			vec3 col(0, 0, 0);
			for (int s = 0; s &lt; ns; s++) { // Anti-aliasing - get ns samples for each pixel
				double u = (i + random_double(0.0, 0.999)) / double(nx);
				double v = (j + random_double(0.0, 0.999)) / double(ny);
				ray r = cam.get_ray(u, v);
				col += color(r, world, maxDepth);
			}

			col /= double(ns); // Average the color between objects/background
			col = vec3(sqrt(col[0]), sqrt(col[1]), sqrt(col[2]));  // set gamma to 2
			int ir = int(255.99 &#42; col[0]);
			int ig = int(255.99 &#42; col[1]);
			int ib = int(255.99 &#42; col[2]);
			std::cout &lt;&lt; ir &lt;&lt; " " &lt;&lt; ig &lt;&lt; " " &lt;&lt; ib &lt;&lt; "\n";
		}
	}
    
	...

}

</code></pre>

<hr />

<p><span class="note">
After writing the next section on Bounding Volume Hierarchies, I decided to refactor - I kept getting confused as to what was a class, a method, or a file. There were some inconsistencies in variable names as well. From here on out, variables and functions are camelCase, and classes and files are capitalized. Sorry if this causes any confusion, but it had to be done!
</span></p>

<h2 id="bounding-volume-hierarchies"><a id="bounding-volume-hierarchies"></a>Bounding Volume Hierarchies</h2>

<p><img alt="BVH Illustration" src="/assets/images/blog-images/path-tracer/the-next-week/bounding-volume-hierarchy-wikipedia.svg" style="background: white; padding: 2rem;" /></p>

<p>Shirley describes this section as the most difficult part - he justfies tackling it now to avoid future refactoring in addition to significantly reducing runtime. Let’s dive in.</p>

<p>If you’d like a succinct primer on the subject, I’d highly reccommend the following video:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/EqvtfIqneKA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p>Calculating ray-object intersections is where our ray tracer spends most of its time - and this time spent increases linearly with the number of objects in a scene. However - as Shirley points out - intersection is a repeated search upon a static model. As such, we should be able to <strong>apply the principles of binary search</strong> (divide and conquer) to our intersection logic.</p>

<p><span class="captioned-image">
<img src="/assets/images/blog-images/path-tracer/the-next-week/binary-vs-linear.gif" alt="Binary vs linear search" />
Average case for binary search (<a href="https://blog.penjee.com/binary-vs-linear-search-animated-gifs/">source</a>)
</span></p>

<p>In order to use a binary sort in any scenario, the data has to be sorted. Consequently, we have to find a way to “sort” our scene. We’ll do this by breaking up the scene into progressively smaller chunks (like a binary tree) using bounding volumes. The most common approaches for sorting ray tracing models are to either bound by space or by scene objects. We’ll be bounding by object, as it’s simpler.</p>

<p>Here’s the “Key Idea” on BVH’s from Shirley’s book:</p>
<blockquote>
  <p>The key idea of a bounding volume over a set of primitives is to find a volume that fully encloses (bounds) all the objects. For example, suppose you computed a bounding sphere of 10 objects. Any ray that misses the bounding sphere definitely misses all ten objects. If the ray hits the bounding sphere, then it might hit one of the ten objects.</p>
</blockquote>

<p>It follows that the pseudo-code looks like this:
&lt;/code&gt;&lt;/pre&gt;
if (ray hits bounding object)
    return whether ray hits bounded objects
else
    return false
&lt;/code&gt;&lt;/pre&gt;</p>

<p>One more important aspect of BVH’s - any object is in <strong>only one bounding volume</strong>, but <strong>bounding volumes can overlap</strong>.</p>

<h3 id="establishing-a-hierarchy"><a id="establishing-a-hierarchy"></a>Establishing a Hierarchy</h3>

<p>To make intersection checks sub-linear, we need to establish a hierarchy. If we had a set of objects split into two subsets - orange &amp; blue - and we used rectangular bounding volumes in our model, this would be the result:</p>

<p><img src="/assets/images/blog-images/path-tracer/the-next-week/bounding-hierarchies.png" alt="BVH Illustration" style="     background: transparent; " /></p>

<p>The orange &amp; blue subsets are simply inside the white rectangle and the binary tree has no order. The pseudo-code for this hierarchy would look like:</p>

<pre><code>
if (hits white)
    hitOrange = hits orange enclosed objects
    hitBlue = hits blue enclosed objects
    if (hitOrange or hitBlue)
        return true and info of closer hit
return false
</code></pre>

<h3 id="understanding-axis-aligned-bounding-boxes-aabbs">Understanding Axis-Aligned Bounding Boxes (AABBs)</h3>

<p>We want our bounding box collisions to be fast and as compact as possible. For this, we’ll implement a popular solution - axis-aligned bounding boxes (AABB’s). These boxes will be “parallelepipeds” - 3d parallelograms. Another option would be to use spheres, but depending on the shape of the object in question, spheres can result in more false positive collisions than a bounding box (Imagine enclosing a person in a sphere vs. in a box).</p>

<p><img src="/assets/images/blog-images/path-tracer/the-next-week/parallelepiped-wiki.svg" alt="Parallelpiped" /></p>

<p>Since these AABB’s are simply containers for our renderable objects, we don’t need any additional information about collisions (like normals, materials, or hit points).</p>

<p>To formulate our AABB’s, we’ll use the slab method. Here’s an explanation from <a href="https://pbr-book.org/3ed-2018/Shapes/Basic_Shape_Interface">pbr-book.org</a>:</p>

<blockquote>
  <p>One way to think of bounding boxes is as the intersection of three slabs, where a slab is the region of space between two parallel planes. To intersect a ray against a box, we intersect the ray against each of the box’s three slabs in turn.</p>
</blockquote>

<p><img src="/assets/images/blog-images/path-tracer/the-next-week/rotating-knot.gif" alt="Rotating knot with dynamic bounding box" /></p>

<p>Let’s start with an AABB example in 2D - a rectangle:</p>

<p>We need see if the ray in question hits the edges of the slab in the x-coordinate space. It will, unless the ray is parallel to the plane.</p>

<p><span class="captioned-image">
    <img src="/assets/images/blog-images/path-tracer/the-next-week/ray-slab-intersect.svg" alt="Slab Intersection" />
    Slab Intersection (with normal $(1,0,0)$)
</span></p>

<p>We now check for ray-slab intersections in the y-coordinate space in the same manner. If there’s any overlap in $x$ and $y$’s $t$ intervals, that’s a collision:</p>

<p><span class="captioned-image">
    <img src="/assets/images/blog-images/path-tracer/the-next-week/ray-aabb-intersect.svg" alt="AABB Intersection" />
    2D AABB Collision 
    </span>
&lt;/span&gt;</p>

<p>In 3D, the edges in question are planes instead of lines. To find where the ray intersects the plane, we can use the function</p>

\[\mathbf{P}(t) = \mathbf{A} + t \mathbf{b}\]

<p>$P$ is a point on the ray.
$A$ is the ray origin.
$b$ is the direction of the ray.
The ray parameter $t$ is a real number (positive or negative) that moves $P(t)$ along the ray.</p>

<p>In terms of $x$, the ray hits the plane $x = x_0$ at $t$ that satisfies the equation</p>

\[x_0 = A_x + t_0 b_x\]

<p>Therefore, $t_0$ and $t_1$ can be calculated as follows, respectively:</p>

\[t_0 = \frac{x_0 - A_x}{b_x}\]

\[t_1 = \frac{x_1 - A_x}{b_x}\]

<h3 id="implementing-aabb-ray-intersections">Implementing AABB Ray Intersections</h3>

<p>The simple pseudocode for collisions using the method described in the previous section is as follows:</p>

<pre><code>
compute (tx0, tx1)
compute (ty0, ty1)
compute (tz0, tz1)
return overlap?( (tx0, tx1), (ty0, ty1), (tz0, tz1))
</code></pre>

<p>There are a couple complications to be aware of:</p>
<ul>
  <li>The ray could be travelling in the negative direction after having bounced off an object or simply based on the camera’s coordinates</li>
  <li>The division of $x_n - A_n$ by $b_n$ could cause infinites</li>
  <li>A ray originating from a slab boundary could result in $NaN$</li>
  <li>SIMD Vectorization issues (Minor and beyond the scope of this post)</li>
</ul>

<p>To get started addressing these issues and more, we should look to our interval computation:</p>

\[t_0 = \frac{x_0 - A_x}{b_x}\]

\[t_1 = \frac{x_1 - A_x}{b_x}\]

<p>One thing to always be wary of is divison by zero. Funnily enough - valid rays that have a $b$ (direction) of 0 (in any coordinate space - x, y, or z) will cause division by zero. Peter mentions that “Also, the zero will have a ± sign under IEEE floating point” - so maybe we won’t <em>technically</em> get a divide by zero - I’m a little unsure of why he mentions this. You can read up on signed zero on <a href="https://en.wikipedia.org/wiki/Signed_zero">Wikipedia</a> or <a href="https://stackoverflow.com/questions/42926763/the-behaviour-of-floating-point-division-by-zero">StackOverflow</a>. Anyway, when $b = 0$, $t_0$ and $t_1$ will both be either +∞ or -∞ if not between coordinate $x_0$ and $x_1$, which means that we can use min and max to get the correct values.</p>

\[t_{x0} = \min(
     \frac{x_0 - A_x}{b_x},
     \frac{x_1 - A_x}{b_x})\]

\[t_{x1} = \max(
    \frac{x_0 - A_x}{b_x},
    \frac{x_1 - A_x}{b_x})\]

<blockquote>
  <p>The remaining troublesome case if we do that is if $b_x=0$ and either $x_0−A_x=0$ or $x_1−A_x=0$ so we get NaN. In that case we can probably accept either hit or no hit answer, but we’ll revisit that later.</p>
</blockquote>

<p>Now we need to think about how we’re going to implement the overlap function - we’re going to assume that the edges are in order - that is, $x_0$ / $y_0$ / $z_0$ is always less than $x_1$ / $y_1$ / $z_1$  Let’s think about it in 2D again:</p>

<p><img src="/assets/images/blog-images/path-tracer/the-next-week/ray-aabb-intersect.svg" alt="AABB Intersection" /></p>

<p>We’re going to simply check if either $y_0$ or $y_1$ are contained within ($x_0$, $x_1$).</p>

<p>We can extend this concept to 3D:</p>

<pre><code>
bool overlap(x0, x1, y0, y1, z0, z1)
    z0 = max(x0, y0)
    z1 = min(x1, y1)
    return (z0 &lt; z1)
</code></pre>

<blockquote>
  <p>If there are any NaNs running around there, the compare will return false so we need to be sure our bounding boxes have a little padding if we care about grazing cases (and we probably should because in a ray tracer all cases come up eventually).</p>
</blockquote>

<p>Translated to C++:</p>

<pre><code class="language-cpp">
#ifndef BOUNDINGBOXH
#define BOUNDINGBOXH

#include "RtWeekend.h"

class BoundingBox {
    public:
        BoundingBox() {}
        BoundingBox(const Vec3&amp; a, const Vec3&amp; b) { minimum = a; maximum = b;}

        vec3 min() const {return minimum; }
        vec3 max() const {return maximum; }

        bool hit(const Ray&amp; r, double tMin, double tMax) const {
            for (int a = 0; a &lt; 3; a++) {
                auto t0 = fmin((minimum[a] - r.origin()[a]) / r.direction()[a],
                               (maximum[a] - r.origin()[a]) / r.direction()[a]);
                auto t1 = fmax((minimum[a] - r.origin()[a]) / r.direction()[a],
                               (maximum[a] - r.origin()[a]) / r.direction()[a]);
                tMin = fmax(t0, tMin);
                tMax = fmin(t1, tMax);
                if (tMax &lt;= tMin)
                    return false;
            }
            return true;
        }

        vec3 minimum;
        vec3 maximum;
};

#endif
</code></pre>

<h3 id="creating-bounding-boxes-for-our-hittables">Creating Bounding Boxes for our Hittables</h3>
<p>We’ll need a function to compute the bounding boxes of hittables. We can create a hierarchy of bounding boxes enclosing all primitives, and the individual primitives (like single spheres) will be the leaves at the bottom of the hierarchy.</p>

<p>Our bounding box function will return a bool because some primitives (like planes) don’t have bounding boxes.</p>

<p>Moving objects will have a bounding box that will enclose the primitive from timeStart to timeEnd.</p>

<p>First, we’ll create a virtual function in <code class="language-plaintext highlighter-rouge">Hittable.h</code>:</p>

<pre><code class="language-diff-cpp diff-highlight">
+ #include "BoundingBox.h"

...

class Hittable {
public: 
	virtual bool hit(const Ray&amp; r, double tMin, double tMax, HitRecord&amp; rec) const = 0;
+	virtual bool generateBoundingBox(double time0, double time1, BoundingBox&amp; outputBox) const = 0;

};
</code></pre>

<p>and override it in <code class="language-plaintext highlighter-rouge">Sphere.h</code>:</p>

<pre><code class="language-cpp">bool Sphere::generateBoundingBox(double timeStart, double timeEnd, BoundingBox&amp; outputBox) const {
	
	
	BoundingBox box0 = BoundingBox(
			centerAt(timeStart) - vec3(radius, radius, radius),
			centerAt(timeStart) + vec3(radius, radius, radius));

	// Sphere is not moving
	if (timeStart-timeEnd &lt; epsilon ) {
		outputBox = box0
		return true;
	}

	else {
		BoundingBox box1 = BoundingBox(
			centerAt(timeEnd) - vec3(radius, radius, radius),
			centerAt(timeEnd) + vec3(radius, radius, radius));
		
		outputBox = generateSurroundingBox(box0, box1)
                return true;
	}

	
}
</code></pre>

<p>We now need to implement the non-member <code class="language-plaintext highlighter-rouge">generateSurroundingBox</code> function in <code class="language-plaintext highlighter-rouge">BoundingBox.h</code>:</p>

<pre><code class="language-cpp">BoundingBox generateSurroundingBox(BoundingBox box0, BoundingBox box1) const {
            
            double x,y,z;

            x = fmin(box0.min().x(), box1.min().x());
            y = fmin(box0.min().y(), box1.min().y());
            z = fmin(box0.min().z(), box1.min().z());

            vec3 min {x, y, z};



            x = fmax(box0.max().x(), box1.max().x());
            y = fmax(box0.max().y(), box1.max().y());
            z = fmax(box0.max().z(), box1.max().z());

            vec3 max {x, y, z};

            return BoundingBox(min, max);
        }
</code></pre>

<h3 id="creating-bounding-boxes-for-lists-of-hittables">Creating Bounding Boxes for Lists of Hittables</h3>

<p>Similarly, we’ll have to add to our <code class="language-plaintext highlighter-rouge">HittableList</code> class:</p>

<pre><code class="language-cpp">
#ifndef HITTABLELISTH
#define HITTABLELISTH

#include "Hittable.h"

class HittableList : public Hittable {
public:
	HittableList() {}
	HittableList(shared_ptr<Hittable> object) { add(object); }

	void clear() { objects.clear(); }
        void add(shared_ptr<Hittable> object) { objects.push_back(object); }
	virtual bool hit(const Ray&amp; r, double tMin, double tMax, HitRecord&amp; rec) const override;
+	virtual bool generateboundingBox(double timeStart, double timeEnd, BoundingBox&amp; outputBox) const override;

	std::vector&lt;shared_ptr<Hittable>&gt; objects;

};

bool HittableList::hit(const Ray&amp; r, double tMin, double tMax, HitRecord&amp; rec) const {
	HitRecord tempHitRec;
	bool hitStatus = false;
	double closestSoFar = tMax;
	for (const auto&amp; object : objects) {

		if (object-&gt;hit(r, tMin, closestSoFar, tempHitRec)) {
			hitStatus = true;
			closestSoFar = tempHitRec.t;
			rec = tempHitRec;
		}
	}
	return hitStatus;
	
}

+   bool HittableList::generateBoundingBox(double timeStart, double timeEnd, BoundingBox &amp;outputBox) const {
+   	
+   	if (objects.empty()) {
+   		return false;
+   	}
+   
+       BoundingBox tempBox;
+       bool isFirstBox = true;
+   
+       for (const auto&amp; object : objects) {
+           if (!object-&gt;generateBoundingBox(timeStart, timeEnd, tempBox)) return false;
+           outputBox = isFirstBox ? tempBox :  generateSurroundingBox(outputBox, tempBox);
+           isFirstBox = false;
+       }
+   
+       return true;
+   	
+   }

#endif // !HITTABLELISTH
&lt;/code&gt;&lt;/pre&gt; 

### Defining our Hittable BVH Class
Our BVHs need to be `hittable`s.

Take note of the fact that the child nodes point to generic `Hittable`s - they can other BVHs, spheres, or any kind of hittable.

<pre><code class="language-cpp">#ifndef BVHH
#define BVHH

#include "RtWeekend.h"

#include "Hittable.h"
#include "HittableList.h"


class BvhNode : public Hittable {
    public:
    
        BvhNode();

        BvhNode(const HittableList&amp; list, double timeStart, double timeEnd)
            : BvhNode(list.objects, 0, list.objects.size(), timeStart, timeEnd)
        {}

        BvhNode(
            const std::vector&lt;shared_ptr<hittable>&gt;&amp; srcObjects,
            size_t start, size_t end, double timeStart, double timeEnd);

        virtual bool hit(
            const Ray&amp; r, double tMin, double tMax, HitRecord&amp; rec) const override;

        virtual bool generateBoundingBox(double timeStart, double timeEnd, BoundingBox&amp; outputBox) const override;

    public:
        shared_ptr<hittable> left;
        shared_ptr<hittable> right;
        BoundingBox box;
};

bool BvhNode::hit(const Ray&amp; r, double tMin, double tMax, HitRecord&amp; rec) const {
    if (!box.hit(r, tMin, tMax))
        return false;

    bool hitLeft = left-&gt;hit(r, tMin, tMax, rec);
    bool hitRight = right-&gt;hit(r, tMin, hitLeft ? rec.t : tMax, rec);

    return hitLeft || hitRight;
}

bool BvhNode::generateBoundingBox(double timeStart, double timeEnd, BoundingBox&amp; outputBox) const {
    outputBox = box;
    return true;
}

#endif
&lt;/code&gt;&lt;/pre&gt;

### Splitting BVH Volumes

&gt; The most complicated part of any efficiency structure, including the BVH, is building it.

These BVHs can be hard to create a mental image for - here's a video to help:
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/rM-BVsdi8c4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

We'll be building the BVH in the constructor. The BVH doesn't have to be perfect - as long as the list of `hittables` in a node gets divided into two sublists, the BVH `hit` function will work. Shirley notes that the best/fastest scenario is if the children `hittable`s have smaller bounding boxes than their parent.

We'll follow Shirley's lead and adopt a simplistic middle-ground method:

1. Randomly choose an axis
2. Sort the primitives
3. Store the primitives as evenly as possible across subtrees

When the incoming `vector` object has a size of two, that's when we can stop recursing and put each of the two hittables in their respective subtrees.

First, let's add a utility function to `RtWeekend.h` to return a random int in a given range:

<pre><code class="language-cpp">inline int randomInt(int min, int max) {
    // Returns a random integer in [min,max].
    return static_cast&lt;int&gt;(randomDouble(min, max+1));
}
</code></pre>

Now we can start forming our BVH class:


<pre><code class="language-cpp">

#ifndef BVHH
#define BVHH

#include &lt;algorithm&gt;
#include "RtWeekend.h"
#include "Hittable.h"
#include "HittableList.h"

class BvhNode : public Hittable {
    public:

        BvhNode();
        BvhNode(const HittableList&amp; list, double timeStart, double timeEnd)
            : BvhNode(list.objects, 0, list.objects.size(), timeStart, timeEnd)
        {}

        BvhNode(
                const std::vector&lt;shared_ptr<Hittable>&gt;&amp; srcObjects,
                size_t start, size_t end, double timeStart, double timeEnd);

        virtual bool hit(
                const Ray&amp; r, double tMin, double tMax, HitRecord&amp; rec) const override;

        virtual bool generateBoundingBox(double timeStart, double timeEnd, BoundingBox&amp; outputBox) const override;

    public:
        shared_ptr<hittable> left;
        shared_ptr<hittable> right;
        BoundingBox box;
};
&lt;/code&gt;&lt;/pre&gt;


Let's define the constructors and member functions:
<pre><code class="language-cpp">


BvhNode::BvhNode(
        std::vectorlt;shared_ptrlt;Hittable&gt;&gt;&amp; srcObjects,
        size_t start, size_t end, double timeStart, double timeEnd
        ) {
    auto objects = srcObjects; // Create a modifiable array of the source scene objects

    // Determine random axis
    int axis = randomInt(0,2);

    // *The comparators will be implemented later on*
    auto comparator = (axis == 0) ? compareX
        : (axis == 1) ? compareY 
        : compareZ;

    size_t objectSpan = end - start;

    // Sort the primitives
    if (objectSpan == 1) {
        left = right = objects[start];
    } else if (objectSpan == 2) {
        if (comparator(objects[start], objects[start+1])) {
            left = objects[start];
            right = objects[start+1];
        } else {
            left = objects[start+1];
            right = objects[start];
        }
    } else {
        std::sort(objects.begin() + start, objects.begin() + end, comparator);

        auto mid = start + objectSpan/2;
        left = make_sharedlt;BvhNode&gt;(objects, start, mid, timeStart, timeEnd);
        right = make_sharedlt;BvhNode&gt;(objects, mid, end, timeStart, timeEnd);
    }

    aabb boxLeft, boxRight;

    if (  !left-&gt;generateBoundingBox (timeStart, timeEnd, boxLeft)
            || !right-&gt;generateBoundingBox(timeStart, timeEnd, boxRight)
       )
        std::cerr lt;lt; "No bounding box in BvhNode constructor.\n";

    box = generateSurroundingBox(boxLeft, boxRight);
}

bool BvhNode::hit(const Ray&amp; r, double tMin, double tMax, HitRecord&amp; rec) const {
    if (!box.hit(r, tMin, tMax))
        return false;

    bool hitLeft = left-&gt;hit(r, tMin, tMax, rec);
    bool hitRight = right-&gt;hit(r, tMin, hitLeft ? rec.t : tMax, rec);

    return hitLeft || hitRight;
}

bool BvhNode::generateBoundingBox(double timeStart, double timeEnd, BoundingBox&amp; outputBox) const {
    outputBox = box;
    return true;
}

#endif

</code></pre> 


### Adding our Box Comparison Functions

First of all, let's define some axis `enum`s in `RtWeekend.h`:
<pre><code class="language-cpp">
...

// Constants
const double infinity = std::numeric_limits<double>::infinity();
const double pi = 3.1415926535897932385;
const double epsilon = 0.00001;

+   // Enums
+   enum Axis { x, y, z };

// Utility Functions
inline double degreesToRadians(double degrees) {
    return degrees * pi / 180;
}
...
&lt;/code&gt;&lt;/pre&gt; 

Now we can add a generic non-member comparator to `BoundingBox` (right above the implementation of our `BvhNode` constructor):

<pre><code class="language-cpp">
inline bool box_compare(const shared_ptr&lt;hittable&gt; a, const shared_ptr&lt;hittable&gt; b, int axis) {
    aabb box_a;
    aabb box_b;

    if (!a-&gt;bounding_box(0,0, box_a) || !b-&gt;bounding_box(0,0, box_b))
        std::cerr &lt;&lt; "No bounding box in bvh_node constructor.\n";

    return box_a.min().e[axis] &lt; box_b.min().e[axis];
}
</code></pre>

and the calls to the comparator (right above the implementation of our `BvhNode` constructor):

<pre><code class="language-cpp">
bool compareX (const shared_ptr<Hittable> a, const shared_ptr<Hittable> b) {
    return compare(a, b, Axis::x);
}

bool compareY (const shared_ptr<Hittable> a, const shared_ptr<Hittable> b) {
    return compare(a, b, Axis::y);
}

bool compareZ (const shared_ptr<Hittable> a, const shared_ptr<Hittable> b) {
    return compare(a, b, Axis::z);
}
&lt;/code&gt;&lt;/pre&gt; 

![Our control image for testing BVH optimization](/assets/images/blog-images/path-tracer/the-next-week/with-bvh.ppm)
The difference in rendering time for the above image is clear:

<pre><code class="language-terminal">
evan@evan-ThinkPad-E495:~/Projects/PathTracer/src$ ./a.out &gt; without-bvh.ppm
Scanlines remaining: 0
Done in:
	1 hours
	9 minutes
	16 seconds.
</code></pre> 

<pre><code class="language-terminal">evan@evan-ThinkPad-E495:~/Projects/PathTracer/src$ ./a.out &gt; with-bvh.ppm 
Scanlines remaining: 0   
Finished in:
	0 hours
	13 minutes
	45 seconds.
</code></pre>


### Implementing Solid Textures
&gt; A texture in graphics usually means a function that makes the colors on a surface procedural.

The aforementioned function could be synthesis, an image lookup, or somewehere in between. We'll start simply by implementing colors as textures.

#### The First Texture: Solid Color

##### Creating our Texture Class


First, let's create our base class `Texture` with the abstract method `value`:
<pre><code class="language-cpp">
#ifndef TEXTUREH
#define TEXTUREH

#include "RtWeekend.h"

class Texture {
	public:
		virtual Color value(double u, double v, const Vec3&amp; p) const = 0;
};
</code></pre> 


Below `Texture` we'll define `SolidColor`:
<pre><code class="language-cpp">
...

class SolidColor : public Texture {
	public:
		SolidColor() {}
		SolidColor(Vec3 c) : ColorValue(c) {}

		SolidColor(double red, double green, double blue)
			: SolidColor(Vec3(red,green,blue)) {}

		virtual Vec3 value(double u, double v, const Vec3&amp; p) const override {
			return ColorValue;
		}

	private:
		Vec3 ColorValue;
};

#endif</code></pre>

Like me, you might be wondering what those `u` and `v` doubles are doing in our `value` function...

##### UV Texture Coordinates for Spheres
![UV Mapping](/assets/images/blog-images/path-tracer/the-next-week/uv-mapping.png) 

As usual, [Wikipedia](https://en.wikipedia.org/wiki/UV_mapping) has an excellent introduction to UV Mapping:
&gt; UV mapping is the 3D modeling process of projecting a 3D model's surface to a 2D image for texture mapping. The letters "U" and "V" denote the axes of the 2D texture because "X", "Y", and "Z" are already used to denote the axes of the 3D object in model space, while "W" (in addition to XYZ) is used in calculating quaternion rotations, a common operation in computer graphics.   
</Hittable></Hittable></Hittable></Hittable></Hittable></Hittable></code></pre></double></code></pre></hittable></hittable></Hittable></code></pre></hittable></hittable></hittable></code></pre></Hittable></Hittable></Hittable></code></pre>]]></content><author><name>Evan</name></author><category term="graphics" /><category term="ray-tracing-in-one-weekend" /><category term="c++" /><summary type="html"><![CDATA[We've created a [straight-forward ray tracer]({{ site.url }}/2020/06/19/ray-tracing-in-one-weekend-part-two.html#post-title) - what more could there be to do? By the time we're done with this segment, we'll have what Peter Shirley calls a "real ray tracer."]]></summary></entry><entry><title type="html">Something to Stare At:</title><link href="http://localhost:4000/2023/04/25/artic-art-fetcher.html" rel="alternate" type="text/html" title="Something to Stare At:" /><published>2023-04-25T17:46:10-04:00</published><updated>2023-04-25T17:46:10-04:00</updated><id>http://localhost:4000/2023/04/25/artic-art-fetcher</id><content type="html" xml:base="http://localhost:4000/2023/04/25/artic-art-fetcher.html"><![CDATA[<p><a id="continue-reading-point"></a>
I’ve had the <a href="/assets\images\blog-images\art-fetcher\old-desktop-wallpaper.png">same desktop wallpaper</a> for almost ten years. I’d like to change it up. I’d also like to feel like an intellectual. Luckily, the <a href="https://www.artic.edu/">Art Institute of Chicago</a> and their <a href="https://api.artic.edu/docs/">API</a> can help me out.</p>

<!--end-excerpt-->

<hr />

<h2 id="contents">Contents</h2>

<ul class="table-of-contents">
    <li><a href="#the-idea">The Idea</a></li>
    <li><a href="#the-gui">The GUI</a></li>
    <ul>
        <li><a href="#the-big-picture">The Big Picture</a></li>
        <ul>
            <li><a href="#creating-a-window">Creating a Window</a></li>
            <li><a href="#creating-a-frame-for-our-window">Creating a Frame for Our Window</a></li>
            <li><a href="#setting-up-frames-within-our-main-frame">Setting Up Frames Within Our Main Frame</a></li>
            <li><a href="#handling-resize">Handling Resize</a></li>
            <li><a href="#changing-frames-to-labelframes">Changing Frames to Labelframes</a></li>
        </ul>
        <li><a href="#creating-the-gui-sections">Creating the GUI Sections</a></li>
        <ul>
            <li><a href="#the-file-management-section">The File Management Section</a></li>
            <li><a href="#the-artwork-criteria-section">The Artwork Criteria Section</a></li>
            <li><a href="#the-logging-pane">The Logging Pane</a></li>
            <li><a href="#the-fetch-button">The Fectch Button</a></li>
        </ul>
    <li><a href="#creating-the-model">Creating the Model</a></li>
        <ul>
            <li><a href="#hooking-up-the-file-management-section">The File Management Section</a></li>
        </ul>
        <li><a href="#creating-the-backend">Creating the Backend</a></li>
        <ul>
            <li><a href="#forming a connection">The File Management Section</a></li>
        </ul>

    </ul>

</ul>

<hr />

<h2 id="the-idea"><a id="the-idea"></a>The Idea</h2>

<p>My plan is to create a simple python GUI for automatically downloading and managing images in a folder to be used by Windows’ slideshow feature. I’d like to allow the user to perform robust queries with parameters such as:</p>

<ul>
  <li>time period</li>
  <li>type of art</li>
  <li>predominant color</li>
  <li>popularity</li>
  <li>medium</li>
</ul>

<p>Additionally, I’ll allow the user to control:</p>

<ul>
  <li>how many images should be in the folder at any time</li>
  <li>how frequently to check for updates</li>
  <li>whatever else feels right</li>
</ul>

<hr />

<h2 id="the-gui"><a id="the-gui"></a>The GUI</h2>

<h2 id="the-big-picture"><a id="the-big picture"></a>The Big Picture</h2>

<p>I figure the GUI is as a good a place as any to start. (<code class="language-plaintext highlighter-rouge">tkinter</code>)[https://docs.python.org/3/library/tkinter.html] is the sole framework that’s built in to the standard Python library, so that’s what we’ll be using here. I have used tkinter before (for my mostly-abandoned <a href="https://github.com/eldun/SausageSolver">‘Sausage Solver’</a> project), but it has been a while, so we’ll get back up to speed together. If you need a more in-depth run-through, check out <a href="https://tkdocs.com/tutorial/firstexample.html">tkdocs.com</a>. Here’s my mockup for the GUI:</p>

<p><a id="mockup"></a>
<span class="captioned-image half-sized-image">
<img src="/assets\images\blog-images\art-fetcher\mockup.png" alt="My first draft for the art fetcher" />
The general idea of the GUI
</span>
<!-- <span class="captioned-image">
![sausage-solver](/assets\images\blog-images\art-fetcher\sausage-solver.png)
My quarter-baked solver GUI from a couple months ago
</span> --></p>

<hr />

<h2 id="creating-a-window"><a id="creating-a-window"></a>Creating a Window</h2>
<p>I’m going to use the <a href="https://stackoverflow.com/a/17470842">template</a> that <a href="https://stackoverflow.com/users/7432/bryan-oakley">Bryan Oakley</a> uses for his tkinter projects. If you’re wondering who Bryan is, have a look at his StackOverflow profile. He’s the top answerer to most tkinter questions I’ve looked up. It’s his thing.</p>

<p>Originally, I coded this GUI in a more procedural manner (like in the <a href="https://tkdocs.com/tutorial/firstexample.html">tkdocs eqample</a>), but it started getting messy.</p>

<p><code class="language-plaintext highlighter-rouge">fetcher.py</code>:</p>
<pre><code class="language-python">
import tkinter as tk    # Standard binding to tk
import tkinter.ttk as ttk    # Binding to ttk submodule for new/prettier themed widgets

class MainApplication(ttk.Frame):
    def __init__(self, parent, *args, **kwargs):
        ttk.Frame.__init__(self, parent, *args, **kwargs)
        self.parent = parent

        &lt;create the rest of your GUI here&gt;

if __name__ == "__main__":
    # Create window
    window = tk.Tk()
    window.title("ArticArtFetcher")
    window.mainloop()
</code></pre>

<p><span class="captioned-image">
<img src="/assets\images\blog-images\art-fetcher\basic-gui-window.png" alt="Our GUI Window" />
Our new GUI window
</span></p>

<hr />

<h2 id="creating-a-frame-for-our-window"><a id="creating-a-frame-for-our-window"></a>Creating a Frame for Our Window</h2>
<p>Our GUI will be visually and logically separated into ‘Frames’. Now that we have a window, we can add a ‘main frame’ to contain the rest of our frames. Why, you ask, do we need a frame for our frames if we already have a window? I had the same question; <a href="https://tkdocs.com/tutorial/firstexample.html">tkdocs</a> addresses it:</p>

<blockquote>
  <p>We could just put the other widgets in our interface directly into the main application window without the intervening content frame. That’s what you’ll see in older Tk programs.</p>

  <p>However, the main window isn’t itself part of the newer “themed” widgets. Its background color doesn’t match the themed widgets we will put inside it. Using a “themed” frame widget to hold the content ensures that the background is correct.</p>

  <p><img src="/assets\images\blog-images\art-fetcher\why-use-main-frame.png" alt="Placing a themed frame inside a window" /></p>
</blockquote>

<pre><code class="language-diff-python diff-highlight">
import tkinter as tk    # Standard binding to tk
import tkinter.ttk as ttk    # Binding to ttk submodule for new/prettier themed widgets

class MainApplication(ttk.Frame):
    def __init__(self, parent, *args, **kwargs):
        super().__init__(self, parent, *args, **kwargs)
        self.parent = parent


if __name__ == "__main__":
    # Create window
    window = tk.Tk()
    window.title("ArticArtFetcher")
+   window.columnconfigure(index=0, weight=1)
+   window.rowconfigure(index=0, weight=1)
+   window.minsize(200, 200)
+
+   # Create frame for window
+   MainApplication(parent=window).grid(column=0, row=0, sticky=(tk.NSEW))

    window.mainloop()
</code></pre>

<p>The outward-facing result is identical:
<span class="half-sized-image">
<img src="/assets\images\blog-images\art-fetcher\basic-gui-window-with-frame.png" alt="Our GUI Window (with Frame)" />
</span></p>

<hr />

<h2 id="setting-up-frames-within-our-main-frame"><a id="setting-up-frames-within-our-main-frame"></a>Setting Up Frames Within Our Main Frame</h2>
<p>I’d like to divide our rudimentary GUI as illustrated in my <a href="#mockup">mockup</a>. We can accomplish that using <a href="https://tkdocs.com/tutorial/complex.html#labelframe">LabelFrames</a>.</p>

<p>The <a href="https://tkdocs.com/tutorial/grid.html">grid geometry manager</a> will be our main tool for creating layouts. All we really have to do is plop in some grid coordinates and tell each widget where to anchor itself with the <code class="language-plaintext highlighter-rouge">sticky</code> attribute. Before we can do that, though, we’ll have to create our new widget classes as illustrated in <a href="https://stackoverflow.com/a/17470842">Bryan Oakley’s StackOverflow answer</a>.</p>

<p><code class="language-plaintext highlighter-rouge">fetcher.py</code>:</p>
<pre><code class="language-diff-python diff-highlight">
+class FileManagementFrame(ttk.Labelframe):
+    pass
+
+        
+class ArtworkCriteriaFrame(ttk.Labelframe):
+    pass
+
+class LogPaneFrame(ttk.Labelframe):
+    pass
+
+class FetchButtonFrame(ttk.Frame):
+    pass        
+
 class MainApplication(ttk.Frame):
     def __init__(self, parent, *args, **kwargs):
         super().__init__(parent, *args, **kwargs)
      
         self.parent = parent
       

+        self.file_management_frame = FileManagementFrame(self, text="File Management", borderwidth=5, relief=tk.RIDGE)
+        self.artwork_criteria_frame = ArtworkCriteriaFrame(self,  text="Artwork Criteria", borderwidth=5, relief=tk.RIDGE)
+        self.log_panel_frame = LogPaneFrame(self,  text="Log", borderwidth=5, relief=tk.RIDGE)
+        self.fetch_button_frame = FetchButtonFrame(self, borderwidth=5, relief=tk.RIDGE)
+
+        self.file_management_frame.grid(column=0, row=0, sticky=(NSEW), padx=10, pady=10)
+        self.artwork_criteria_frame.grid(column=1, row=0, sticky=(NSEW), padx=10, pady=10)
+        self.log_panel_frame.grid(column=0, row=1, sticky=(NSEW), padx=10, pady=10)
+        self.fetch_button_frame.grid(column=1, row=2, padx=10, pady=5, sticky=NSEW)


if __name__ == "__main__":
    # Create window
    window = tk.Tk()
    window.title("ArticArtFetcher")
    window.columnconfigure(index=0, weight=1)
    window.rowconfigure(index=0, weight=1)
    window.minsize(200, 200)


    # Create frame for window
    MainApplication(parent=window).grid(column=0, row=0 sticky=(tk.NSEW))

    window.mainloop()
</code></pre>

<p>When you run this code, you’ll end up with an empty window. What’s wrong? For one, our Labelframes have nothing in them. Secondly, the rows and columns aren’t configured to resize (we’ll address resizing in the next section).</p>

<blockquote>
  <p>The size of a frame is determined by the size and layout of any widgets within it. In turn, this is controlled by the geometry manager that manages the contents of the frame itself.</p>
</blockquote>

<p><a href="https://tkdocs.com/tutorial/widgets.html#frame">-tkdocs</a></p>

<p>Let’s add some placeholder labels, just to see how things look.</p>

<p><code class="language-plaintext highlighter-rouge">fetcher.py</code>:</p>
<pre><code class="language-diff-python diff-highlight">
class FileManagementFrame(ttk.Labelframe):
-   pass
+   def __init__(self, parent, *args, **kwargs):
+       super().__init__(parent, *args, **kwargs)
+       tk.Label(master=self, text="file management").grid()
        
class ArtworkCriteriaFrame(ttk.Labelframe):
-   pass
+   def __init__(self, parent, *args, **kwargs):
+       super().__init__(parent, *args, **kwargs)    
+       tk.Label(master=self, text="artwork").grid()

class LogPaneFrame(ttk.Labelframe):
-   pass
+   def __init__(self, parent, *args, **kwargs):
+       super().__init__(parent, *args, **kwargs)   
+       tk.Label(master=self, text="log").grid()
 
class FetchButtonFrame(ttk.Frame):   
-   pass
+   def __init__(self, parent, *args, **kwargs):
+       super().__init__(parent, *args, **kwargs)    
+       tk.Label(master=self, text="fetch art").grid()
</code></pre>

<p><span class="row">
    <span class="captioned-image">
        <img src="/assets\images\blog-images\art-fetcher\basic-gui-window-with-empty-labelframes.png" alt="Empty Labelframes" />
Before
    </span>
    <span class="captioned-image">
        <img src="/assets\images\blog-images\art-fetcher\basic-gui-with-filled-labelframes.png" alt="Labelframes with placeholder widgets" />
After
    </span>
</span></p>

<hr />

<h2 id="handling-resize"><a id="handling-resize"></a>Handling Resize</h2>

<p>If we try to resize our nice little window, things look bad:</p>

<p><span class="row">
    <span class="captioned-image">
        <img src="/assets\images\blog-images\art-fetcher\basic-gui-with-filled-labelframes.png" alt="Initial window" />
Initial
    </span>
    <span class="captioned-image">
        <img src="/assets\images\blog-images\art-fetcher\basic-gui-window-bad-resize.png" alt="Poorly Resized GUI" />
Resized
    </span>
</span></p>

<p>What’s wrong here? lets turn to the <a href="https://tkdocs.com/tutorial/grid.html#resize">tkdocs</a>:</p>

<blockquote>
  <p>It looks like sticky may tell Tk <em>how</em> to react if the cell’s row or column does resize but doesn’t actually say that the row or columns <em>should</em> resize if any extra room becomes available.</p>

  <p>Every column and row in the grid has a weight option associated with it. This tells grid how much the column or row should grow if there is extra room in the master to fill. By default, the weight of each column or row is 0, meaning it won’t expand to fill any extra space.</p>

  <p>For the user interface to resize, we’ll need to specify a positive weight to the columns and rows that we’d like to expand. You must provide weights for at least one column and one row. This is done using the <code class="language-plaintext highlighter-rouge">columnconfigure</code> and <code class="language-plaintext highlighter-rouge">rowconfigure</code> methods of grid. This weight is relative. If two columns have the same weight, they’ll expand at the same rate. In our example, we’ll give the three leftmost columns (holding the checkboxes) weights of 3 and the two rightmost columns weights of 1. For every one pixel the right columns grow, the left columns will grow by three pixels. So as the window grows larger, most of the extra space will go to the left side.</p>

  <p><img src="/assets\images\blog-images\art-fetcher\column-weight-example.png" alt="Column weight example" /></p>
</blockquote>

<p>For posterity - <code class="language-plaintext highlighter-rouge">columnconfigure</code> and <code class="language-plaintext highlighter-rouge">rowconfigure</code> also take a <code class="language-plaintext highlighter-rouge">minsize</code> grid option.</p>

<p>By adding a couple config lines, we get a resizable GUI that is looking ever closer to the mockup:</p>

<p><code class="language-plaintext highlighter-rouge">fetcher.py</code>:</p>
<pre><code class="language-diff-python diff-highlight">
...

if __name__ == "__main__":
    # Create window
    window = tk.Tk()
    window.title("ArticArtFetcher")
    window.columnconfigure(index=0, weight=1)
    window.rowconfigure(index=0, weight=1)
    window.minsize(200, 200)

    # Create frame for window
    main_application = MainApplication(parent=window)
    main_application.grid(column=0, row=0, sticky=(tk.NSEW))

    # Configure resize
+   main_application.columnconfigure(index=0, weight=1)
+   main_application.columnconfigure(index=1, weight=1)
+   main_application.rowconfigure(index=0, weight=1)
+   main_application.rowconfigure(index=1, weight=1)
+   main_application.rowconfigure(index=2, weight=1)

    window.mainloop()

</code></pre>

<p>In fact, we don’t even need placeholder labels now that the geometry manager has been configured:</p>

<p><span class="row">
    <span class="captioned-image">
        <img src="/assets\images\blog-images\art-fetcher\basic-gui-with-filled-labelframes.png" alt="Initial window" />
Initial
    </span>
    <span class="captioned-image">
        <img src="/assets\images\blog-images\art-fetcher\basic-gui-window-bad-resize.png" alt="Poorly Resized GUI" />
Resized without weight configuration
    </span>
        <span class="captioned-image">
        <img src="/assets\images\blog-images\art-fetcher\basic-gui-window-good-resize.png" alt="Properly Resized GUI" />
Resized with weight configuration
    </span> 
    <span class="captioned-image">
        <img src="/assets\images\blog-images\art-fetcher\basic-gui-window-good-resize-labels-removed.png" alt="Properly Resized GUI" />
Resized with placeholder labels removed
    </span>
</span></p>

<hr />

<h2 id="the-file-management-section"><a id="the-file-management-section"></a>The File Management Section</h2>

<p>There are a few things I know I want the user to be able to control in regards to the filesystem. I’m sure I’ll think of more features once the program is actually usable. Here’s my list (for now):</p>

<ul>
  <li>Directory selector</li>
  <li>Maximum picture count</li>
  <li>Maximum folder size</li>
  <li>Auto-delete</li>
  <li>Download frequency</li>
  <li>Description (either as .txt file on desktop or by finding a way to incorporate text into image)</li>
</ul>

<p>Here’s the code to set up a dummy version of what I want within the <code class="language-plaintext highlighter-rouge">FileManagementFrame</code> class. The widgets we’re using are assigned to a variable so that we can later retrieve their values in <code class="language-plaintext highlighter-rouge">controller.py</code>.</p>

<p><code class="language-plaintext highlighter-rouge">fetcher.py</code>:</p>
<pre><code class="language-diff-python diff-highlight">

import tkinter as tk    # Standard binding to tk
import tkinter.ttk as ttk    # Binding to ttk submodule for new/prettier themed widgets
from tkinter.constants import NSEW, NE, NW, SE, SW, N, S, E, W   # Standard binding to tk
import tkinter.filedialog as filedialog


+ class FileManagementFrame(ttk.Labelframe):
+     def __init__(self, parent, *args, **kwargs):
+         super().__init__(parent, *args, **kwargs)
+ 
+         # Populate file management section

         # Directory selection
        self.output_directory = tk.StringVar()
        self.output_directory.set("No Directory Selected")
        tk.Label(self, text="Artwork Directory: ").grid(column=0, row=0, sticky=W)
        tk.Label(self, textvariable=self.output_directory).grid(column=1, row=0, sticky=W)
        ttk.Button(self, text="Choose Directory", command=self.choose_directory).grid(column=2, row=0)


        # 'Max pic count' options
        ttk.Label(self, text="Max Picture Count:").grid(column=0, row=1, sticky=W)
        self.max_picture_count_entry = ttk.Entry(self, width=7)
        self.max_picture_count_entry.grid(column=2, row=1)


        # Max folder size
        ttk.Label(self, text="Max Folder Size:").grid(column=0, row=2, sticky=W)
        max_size_frame = ttk.Frame(self)

        self.max_folder_size_entry = ttk.Entry(max_size_frame, width=4)
        self.max_folder_size_entry.grid(column=0, row=0)

        self.folder_size_units_combobox = ttk.Combobox(max_size_frame, width=2)
        self.folder_size_units_combobox['values'] = ('MB', 'GB', 'TB')
        self.folder_size_units_combobox.state(['readonly'])
        self.folder_size_units_combobox.grid(column=1, row=0)

        max_size_frame.grid(column=2, row=2)

        # Auto Delete option
        ttk.Label(self, text="Auto-delete old files:").grid(column=0, row=3, sticky=W)
        # For whatever reason, I have to create a variable to hold the value of the checkbox instead of just getting the widget itself
        self.auto_delete_checkbutton_var = tk.BooleanVar()
        self.auto_delete_checkbutton = tk.Checkbutton(self, anchor=CENTER, variable=self.auto_delete_checkbutton_var)
        self.auto_delete_checkbutton.grid(column=2, row=3, sticky=EW)

        # Update frequency option
        ttk.Label(self, text="Download new files every:").grid(column=0, row=4, sticky=W)

        update_frequency_frame = ttk.Frame(self)
        self.update_frequency_entry = ttk.Entry(update_frequency_frame, width=3)
        self.update_frequency_entry.grid(column=0, row=0)
        self.art_check_frequency_combobox = ttk.Combobox(update_frequency_frame, width=5)
        self.art_check_frequency_combobox['values'] = ('Hours', 'Days', 'Weeks', 'Months')
        self.art_check_frequency_combobox.state(['readonly'])
        self.art_check_frequency_combobox.grid(column=1, row=0)
        update_frequency_frame.grid(column=2,row=4)

        # Description file option
        
        ttk.Label(self, text="Create artwork description file on desktop:").grid(column=0, row=5, sticky=W, columnspan=2)
        # For whatever reason, I have to create a variable to hold the value of the checkbox instead of just getting the widget itself
        self.create_description_checkbutton_var = tk.BooleanVar()
        self.create_description_checkbutton = tk.Checkbutton(self, anchor=CENTER, variable=self.create_description_checkbutton_var)
        self.create_description_checkbutton.grid(column=2, row=5, sticky=EW)

        self.columnconfigure(index=0, weight=1)
        self.columnconfigure(index=1, weight=0)
        self.columnconfigure(index=2, weight=1)

        configure_frame_row_resize(self)
        
        add_widget_padding(self)

    def choose_directory(self):
        dir = filedialog.askdirectory(mustexist=True)

        self.output_directory.set(dir)

</code></pre>

<p><span class="half-sized-image">
<img src="\assets\images\blog-images\art-fetcher\dummy-file-management-section.png" alt="Dummy file management section" /></span></p>

<p>As will be the case with the other sections, we’ll hook up everything with callbacks further down the line.</p>

<h2 id="the-artwork-criteria-section"><a id="the-artwork-criteria-section"></a>The Artwork Criteria Section</h2>

<p>Here’s a short list of some criteria that may be worth filtering by:</p>

<ul>
  <li>time period</li>
  <li>artist</li>
  <li>type of art (e.g. painting, sculpture, book)</li>
  <li>predominant color</li>
  <li>popularity</li>
  <li>style (e.g. impressionist, abstract)</li>
  <li>theme</li>
</ul>

<p>More may come later. I think it’d also be neat to choose images based on the current weather and time - but that may belong in the file management section, once they’re already downloaded. I’m getting ahead of myself - let’s populate our art section in our GUI with dummy widgets!</p>

<p><code class="language-plaintext highlighter-rouge">fetcher.py</code>:</p>
<pre><code class="language-diff-python diff-highlight">
...


class ArtworkCriteriaFrame(ttk.Labelframe):

    def on_choose_color(self):
            colorchooser.askcolor()

    def __init__(self, parent, *args, **kwargs):
        super().__init__(parent, *args, **kwargs)

        # Date range        
        current_row = 0
        ttk.Label(self, text="Date Range (Inclusive)").grid(column=0, row=current_row, sticky=W)
        date_range = ttk.Frame(master=self)
        self.date_start_entry = ttk.Entry(date_range, width=5)
        self.date_start_entry.grid(column=0, row=current_row)

        self.date_start_age = ttk.Combobox(date_range, width=3)
        self.date_start_age['values'] = ('BC','AD')
        self.date_start_age.current(0)
        self.date_start_age.grid(column=1, row=current_row)
        ttk.Label(date_range, text="-").grid(column=2, row=current_row)

        self.date_end_entry = ttk.Entry(date_range, width=5)
        self.date_end_entry.grid(column=3, row=current_row)
        self.date_end_age = ttk.Combobox(date_range, width=3)
        self.date_end_age['values'] = ('BC','AD')
        self.date_end_age.current(0)
        self.date_end_age.grid(column=4, row=current_row)
        date_range.grid(column=2, row=current_row)

        # Artist
        current_row += 1
        ttk.Label(self, text="Artist").grid(column=0, row=current_row, sticky=W)
        self.artist_combobox = ttk.Combobox(self, width=12)
        self.artist_combobox.grid(column=2, row=current_row)

        # Art type(e.g. painting, sculpture, etc.)
        current_row += 1
        ttk.Label(self, text="Type").grid(column=0, row=current_row, sticky=W)
        self.art_type_combobox = ttk.Combobox(self, width=12)
        self.art_type_combobox.grid(column=2, row=current_row)

        # Color
        current_row += 1        
        ttk.Label(self, text="Predominant Color").grid(column=0, row=current_row, sticky=W)
        color_frame = ttk.Frame(self)
        ttk.Button(color_frame, command=self.on_choose_color).grid(column=0, row=0, sticky=EW)
        self.choose_color_entry = ttk.Entry(color_frame, width=7)
        self.choose_color_entry.grid(column=1, row=0, sticky=E)
        color_frame.grid(column=2, row=current_row)

        # Rarity
        current_row += 1
        ttk.Label(self, text="Fetch rarely viewed art").grid(column=0, row=current_row, sticky=W)
        self.rarity_checkbutton_var = tk.BooleanVar()
        tk.Checkbutton(self, variable=self.rarity_checkbutton_var).grid(column=2, row=current_row, sticky=EW)

        # Style (e.g. impressionist, abstract, etc.)
        current_row += 1
        ttk.Label(self, text="Style").grid(column=0, row=current_row, sticky=W)
        self.style_combobox = ttk.Combobox(self, width=12)
        self.style_combobox.grid(column=2, row=current_row)



        self.columnconfigure(index=0, weight=1)
        self.columnconfigure(index=1, weight=0)
        self.columnconfigure(index=2, weight=1)


        configure_frame_row_resize(self)

        add_widget_padding(self)

...

def configure_frame_row_resize(frame):
    for row in range(frame.grid_size()[1]):
        frame.rowconfigure(row, weight=1)

def add_widget_padding(frame):
    for widget in frame.winfo_children():
        widget.grid_configure(padx=5, pady=5)
        add_widget_padding(widget)


...

if __name__ == "__main__":
    # Create window
    window = tk.Tk()
    window.title("ArticArtFetcher")
    window.columnconfigure(index=0, weight=1)
    window.rowconfigure(index=0, weight=1)
+    window.minsize(800, 800)

    # Create frame for window
    main_application = MainApplication(parent=window)
    main_application.grid(column=0, row=0, sticky=(tk.NSEW))

    # Configure resize
    main_application.columnconfigure(index=0, weight=1)
    main_application.columnconfigure(index=1, weight=1)
    main_application.rowconfigure(index=0, weight=1)
    main_application.rowconfigure(index=1, weight=1)
    main_application.rowconfigure(index=2, weight=1)



</code></pre>

<p>There we have it! Note that I also configured the minsize of the rows and columns.</p>

<h2 id="the-logging-pane"><a id="the-logging-pane"></a>The Logging Pane</h2>
<p>Thankfully, there’s a module for basic scrolling text widget, which makes this section pretty straightforward:</p>

<p><code class="language-plaintext highlighter-rouge">fetcher.py</code>:</p>
<pre><code class="language-python">
class LogPaneFrame(ttk.Labelframe):

    def __init__(self, parent, *args, **kwargs):
        super().__init__(parent, *args, **kwargs)

        self.scrolled_text = scrolledtext.ScrolledText(master=self)
        self.scrolled_text.configure(state=tk.DISABLED, background='light gray')
        self.scrolled_text.tag_config('warning', background='black', foreground='red')
        self.scrolled_text.tag_config('success', background='black', foreground='green')

        self.scrolled_text.grid(column=0, row=0, sticky=NSEW)


        self.columnconfigure(index=0, weight=1)
        self.rowconfigure(index=0, weight=1, minsize=10)
        configure_frame_row_resize(self)

    def log_message(self, message, tag=None):
        
        self.scrolled_text.configure(state=tk.NORMAL)
        self.scrolled_text.insert(tk.END,"\n" + message + "\n", tag)
        self.scrolled_text.configure(state=tk.DISABLED)
</code></pre>

<h2 id="the-fetch-button"><a id="the-fetch-button"></a>The Fetch Button</h2>

<p><code class="language-plaintext highlighter-rouge">fetcher.py</code>:</p>
<pre><code class="language-python">
class FetchButtonFrame(ttk.Frame):
    def __init__(self, parent, *args, **kwargs):
        super().__init__(parent, *args, **kwargs)
        ttk.Button(self, text="Fetch").grid(column=0, row=0, sticky=NSEW)

        self.rowconfigure(0, weight=1)
        self.columnconfigure(0, weight=1)
</code></pre>

<p><span class="captioned-image">
<img src="\assets\images\blog-images\art-fetcher\dummy-gui.png" alt="Dummy GUI" />
Our dummy GUI
</span></p>

<h2 id="creating-the-model"><a id="creating-the-model"></a>Creating the Model</h2>

<p>As you may know, the view component of the <a href="https://developer.mozilla.org/en-US/docs/Glossary/MVC">Model-View-Controller (MVC) design pattern</a> is “dumb” - it doesn’t store any data - it merely represents the data stored within the model. First, let’s refactor our files to more closely follow the principles of MVC.</p>

<p>We’ll move all of our <code class="language-plaintext highlighter-rouge">fetcher.py</code> code into <code class="language-plaintext highlighter-rouge">view.py</code> except for the <code class="language-plaintext highlighter-rouge">__main__</code> section.</p>

<p><code class="language-plaintext highlighter-rouge">view.py</code>:</p>
<pre><code class="language-python diff-highlight">
import tkinter as tk    # Standard binding to tk
import tkinter.ttk as ttk    # Binding to ttk submodule for new/prettier themed widgets
from tkinter.constants import CENTER, EW, NSEW, NE, NW, SE, SW, N, S, E, W   # Standard binding to tk
import tkinter.filedialog as filedialog
import tkinter.colorchooser as colorchooser
import tkinter.scrolledtext as scrolledtext

class FileManagementFrame(ttk.Labelframe):
    ...

class ArtworkCriteriaFrame(ttk.Labelframe):

    ...
  
class LogPaneFrame(ttk.Labelframe):

    ...

class FetchButtonFrame(ttk.Frame):
    ...

class MainApplication(ttk.Frame):
    ...
</code></pre>

<p>That leaves <code class="language-plaintext highlighter-rouge">fetcher.py</code> (with a few minor changes):</p>
<pre><code class="language-diff-python diff-highlight">
+ import tkinter as tk
+ import view

if __name__ == "__main__":
    # Create window
    window = tk.Tk()
    window.title("ArticArtFetcher")
    window.columnconfigure(index=0, weight=1)
    window.rowconfigure(index=0, weight=1)
    window.minsize(800,400)

    # Create frame for window
+   main_application = view.MainApplication(parent=window)
    main_application.grid(column=0, row=0, sticky=(tk.NSEW))

    # Configure resize
    main_application.columnconfigure(index=0, weight=1)
    main_application.columnconfigure(index=1, weight=1)
    # Log pane should be the only row that shrinks/resizes
    main_application.rowconfigure(index=1, weight=1)


    window.mainloop()
</code></pre>

<p>This will be our point of entry. The model, view, and (eventually) the controller will be conveniently separated from here onwards.</p>

<p>Now we can get to work designing our model. Create a file by the name of <code class="language-plaintext highlighter-rouge">model.py</code> in the root folder, and we’ll continue on section by section.</p>

<h3 id="the-file-management-section-1"><a id="the-file-management-section"></a>The File Management Section</h3>
<p>Let’s take a look at our GUI and build our model accordingly.
<img src="\assets\images\blog-images\art-fetcher\dummy-gui.png" alt="Dummy GUI" /></p>

<p>We’ll start with some placeholders for all of our options:</p>

<p><code class="language-plaintext highlighter-rouge">model.py</code>:</p>
<pre><code class="language-python">

class Model():
    def __init__(self):
        self.file_management_model = FileManagementModel()
        self.artwork_criteria_model = ArtworkCriteriaModel()


class FileManagementModel():
    def __init__(self):
        self.directory = None
        self.max_picture_count = None
        self.max_folder_size = None
        self.max_folder_size_units = None
        self.auto_delete = None
        self.download_frequency = None
        self.download_frequency_units = None
        self.create_description = None


class ArtworkCriteriaModel():
    def __init__(self):
        self.date_start = None
        self.date_start_era = None
        self.date_end = None
        self.date_end_era = None
        self.artist = None
        self.type = None
        self.predominant_color = None
        self.fetch_rare_art = None
        self.style = None
</code></pre>

<p>We can later turn these attributes into <a href="https://www.programiz.com/python-programming/property">properties</a> to implement business logic/constraints.</p>

<p>We’ll need a way to change these values when the user interacts with the view, which we can accomplish by using tkinter’s <code class="language-plaintext highlighter-rouge">bind()</code> function - covered in the next section.</p>

<h3 id="binding-view-interactions-to-the-controller"><a id="binding-view-interactions-to-the-conntroller"></a>Binding View Interactions to the Controller</h3>

<p><img src="\assets\images\blog-images\art-fetcher\model-view-controller.png" alt="MVC Pattern" /></p>

<p>The first order of business is allowing the view to reference the controller:</p>

<p><code class="language-plaintext highlighter-rouge">view.py</code>:</p>
<pre><code class="language-diff-python diff-highlight">
class MainApplication(ttk.Frame):
    def __init__(self, parent, *args, **kwargs):
        super().__init__(parent, *args, **kwargs)

        self.parent = parent
+       self.controller = None

        ...

+   def set_controller(self, controller):
+       self.controller = controller
</code></pre>

<p><code class="language-plaintext highlighter-rouge">controller.py</code>:</p>
<pre><code class="language-diff-python diff-highlight">
class Controller():
    def __init__(self, view):
        self.view = view
</code></pre>

<p><code class="language-plaintext highlighter-rouge">fetcher.py</code>:</p>
<pre><code class="language-diff-python diff-highlight">
import tkinter as tk
+ import model, view, controller

if __name__ == "__main__":
    # Create window
    window = tk.Tk()

    ...

    # Log pane should be the only row that shrinks/resizes
    main_application.rowconfigure(index=1, weight=1)

+   view = main_application
+   controller = controller.Controller()
+   view.set_controller(controller)

    window.mainloop()
</code></pre>

<p>At this point, we can use <a href="https://docs.python.org/3/library/tkinter.html?highlight=bind#bindings-and-events">tkinter’s <code class="language-plaintext highlighter-rouge">bind</code> function</a> to invoke certain functions upon certain actions. Some widgets have binding as a keyword parameter(called <code class="language-plaintext highlighter-rouge">command</code>), like <code class="language-plaintext highlighter-rouge">Button</code>. However, we can just use <code class="language-plaintext highlighter-rouge">bind()</code> on whichever widget we desire.</p>

<p>I believe in our situation, it makes the most sense to simply send all the values from the view to the model when the user clicks fetch (We’ll cover validation later). Let’s bind the fetch button to a controller function:</p>

<p><code class="language-plaintext highlighter-rouge">controller.py</code>:</p>
<pre><code class="language-diff-python diff-highlight">
class Controller():
    def __init__(self, view):
        self.view = view

+    def on_fetch_button_clicked(self, event):
+        print("fetch clicked")

</code></pre>

<p><code class="language-plaintext highlighter-rouge">view.py</code>:</p>
<pre><code class="language-diff-python diff-highlight">
...

class FetchButtonFrame(ttk.Frame):
    def __init__(self, parent, *args, **kwargs):
        super().__init__(parent, *args, **kwargs)
-        tk.Button(self, text="Fetch", bg='light green').grid(column=0, row=0, sticky=NSEW)
+        self.fetch_button = tk.Button(self, text="Fetch", bg='light green')
+        self.fetch_button.grid(column=0, row=0, sticky=NSEW)

        self.rowconfigure(0, weight=1)
        self.columnconfigure(0, weight=1)

...

class MainApplication(ttk.Frame):
    def __init__(self, parent, *args, **kwargs):
        ...

+    def configure_bindings(self):
+        self.fetch_button_frame.fetch_button.bind(sequence="&amp;ltButtonPress&amp;gt", func=self.controller.on_fetch_button_clicked)
</code></pre>

<p>Note that we had to split up the instantiation and <code class="language-plaintext highlighter-rouge">grid()</code>ing of <code class="language-plaintext highlighter-rouge">fetch_button</code>. This is because grid always returns <code class="language-plaintext highlighter-rouge">None</code>, which is no good because we’re going to want to reference the button in <code class="language-plaintext highlighter-rouge">configure_bindings</code>.</p>

<p>If you run the program and click fetch, you’ll see “fetch clicked” in the console.</p>

<h3 id="performing-preliminary-validation-in-the-view"><a id="performing-preliminary-validation-in-the-view"></a>Performing Preliminary Validation in the View</h3>

<p>It’s a good idea - before sending our user’s input to the controller - to do some simple validation in the view - such as only allowing integers in the “Max Picture Count” field. Let’s follow the <a href="https://anzeljg.github.io/rin2/book2/2405/docs/tkinter/entry-validation.html">doc</a>.</p>

<p>(Sculpting the data for the API will take place in the controller, and ensuring that the data “makes sense”(business logic) will take place in the model.)</p>

<blockquote>
  <ol>
    <li>Write a callback function that checks the text in the Entry and returns <code class="language-plaintext highlighter-rouge">True</code> if the text is valid, or <code class="language-plaintext highlighter-rouge">False</code> if not. If the callback returns <code class="language-plaintext highlighter-rouge">False</code>, the user’s attempt to edit the text will be refused, and the text will be unchanged.</li>
  </ol>
</blockquote>

<p>Let’s create a function for validating int-only entries. We’ll just make it a <a href="https://stackoverflow.com/a/11788267">module function</a>, like <code class="language-plaintext highlighter-rouge">configure_frame_row_resize</code> and <code class="language-plaintext highlighter-rouge">add_widget_padding</code>, since it’ll be used across frames.</p>

<p><code class="language-plaintext highlighter-rouge">view.py</code>:</p>
<pre><code class="language-diff-python diff-highlight">

def on_int_entry_edited(text):
    if str.isdigit(text) or text == "":
        return True
    else:
        return False
</code></pre>

<blockquote>
  <ol>
    <li>Register the callback function. In this step, you will produce a Tcl wrapper around a Python function.</li>
  </ol>

  <p>Suppose your callback function is a function named <code class="language-plaintext highlighter-rouge">isOkay</code>. To register this function, use the universal widget method <code class="language-plaintext highlighter-rouge">.register(isOkay)</code>. This method returns a character string that Tkinter can use to call your function.</p>
</blockquote>

<p><code class="language-plaintext highlighter-rouge">view.py</code>:</p>
<pre><code class="language-diff-python diff-highlight">

class FileManagementFrame(ttk.Labelframe):
    def __init__(self, parent, *args, **kwargs):

        ...

        # 'Max pic count' options
        ttk.Label(self, text="Max Picture Count:").grid(column=0, row=1, sticky=W)
        self.max_picture_count_entry = ttk.Entry(self, width=7)
        self.max_picture_count_entry.grid(column=2, row=1)

+       int_validaiton_command = self.max_picture_count_entry.register(on_int_entry_edited)

</code></pre>

<blockquote>
  <ol>
    <li>When you call the Entry constructor, use the <code class="language-plaintext highlighter-rouge">validatecommand</code> option in the Entry constructor to specify your callback, and use the <code class="language-plaintext highlighter-rouge">validate</code> option to specify when the callback will be called to validate the text in the callback.</li>
  </ol>
</blockquote>

<p>See <a href="https://anzeljg.github.io/rin2/book2/2405/docs/tkinter/entry-validation.html">here</a> for a list of options. We’ll just be using ‘all’.</p>

<p><code class="language-plaintext highlighter-rouge">view.py</code>:</p>
<pre><code class="language-diff-python diff-highlight">

class FileManagementFrame(ttk.Labelframe):
    def __init__(self, parent, *args, **kwargs):

        ...

        # 'Max pic count' options
        ttk.Label(self, text="Max Picture Count:").grid(column=0, row=1, sticky=W)
        self.max_picture_count_entry = ttk.Entry(self, width=7)
        self.max_picture_count_entry.grid(column=2, row=1)

        self.max_picture_count_entry.register(on_int_entry_edited)
        self.max_picture_count_entry.config(validate='all', validatecommand=(int_validaiton_command, '%P'))

</code></pre>

<p>Note the <code class="language-plaintext highlighter-rouge">'%P'</code> in our <code class="language-plaintext highlighter-rouge">validatecommand</code> argument. This is a substituiton code describing the value that the text will have if the change is allowed. You can find all the substituiton codes and how to use them <a href="https://anzeljg.github.io/rin2/book2/2405/docs/tkinter/entry-validation.html">here</a>.</p>

<p>You can now use this validation method with other int-only fields, like “Max Folder Size”:</p>

<p><code class="language-plaintext highlighter-rouge">view.py</code>:</p>
<pre><code class="language-diff-python diff-highlight">
    ...

    # Max folder size
    ttk.Label(self, text="Max Folder Size:").grid(column=0, row=2, sticky=W)
    max_size_frame = ttk.Frame(self)

    self.max_folder_size_entry = ttk.Entry(max_size_frame, width=4)
    self.max_folder_size_entry.grid(column=0, row=0)
+   self.max_folder_size_entry.config(validate='all', validatecommand=(int_validaiton_command, '%P'))

...
</code></pre>

<h3 id="getting-view-data-to-the-model"><a id="getting-view-data-to-the-model"></a>Getting View Data to the Model</h3>

<p>Let’s start by passing the instance of our model to our controller:</p>

<p><code class="language-plaintext highlighter-rouge">fetcher.py</code>:</p>
<pre><code class="language-diff-python diff-highlight">

...

+    model = model.Model()
    view = main_application
+    controller = controller.Controller(model, view)

    view.set_controller(controller)
    view.configure_bindings()

    window.mainloop()
</code></pre>

<p>And then setting our model attributes to the values entered in the view:</p>

<p><code class="language-plaintext highlighter-rouge">controller.py</code>:</p>
<pre><code class="language-diff-python diff-highlight">

class Controller():
    def __init__(self, model, view):
+        self.model = model
        self.view = view

    def on_fetch_button_clicked(self, event):

+        self.update_file_management_model()
+        self.update_file_artwork_criteria_model()
        

    def update_file_management_model(self):
        model = self.model.file_management_model
        view = self.view.file_management_frame


        try:

            model.output_directory = view.output_directory
            model.max_picture_count = view.max_picture_count_entry.get()
            model.max_folder_size = view.max_folder_size_entry.get()
            model.max_folder_size_units = view.folder_size_units_combobox.get()
            model.auto_delete = view.auto_delete_checkbutton_var.get()
            model.download_frequency = view.update_frequency_entry.get()
            model.download_frequency_units = view.art_check_frequency_combobox.get()
            model.create_description = view.create_description_checkbutton_var.get()
        
        except Exception as e:
            self.log_message("Error updating File Management Model:\n" + str(e), 'warning')

        else:
            self.log_model_fields(model)

    def update_file_artwork_criteria_model(self):

        model = self.model.artwork_criteria_model
        view = self.view.artwork_criteria_frame

        try:

            model.date_start = view.date_start_entry.get()
            model.date_start_age = view.date_start_age.get()
            model.date_end = view.date_end_entry.get()
            model.date_end_age = view.date_end_age.get()
            model.artist = view.artist_combobox.get()
            model.type = view.art_type_combobox.get()
            model.predominant_color = view.choose_color_entry.get()
            model.fetch_rare_art = view.rarity_checkbutton_var.get()
            model.style = view.style_combobox.get()

        except Exception as e:
            self.log_message("Error updating File Management Model:\n" + str(e), 'warning')

        else:
            self.log_model_fields(model)

</code></pre>

<h2 id="creating-the-backend"><a id="creating-the-backend"></a>Creating the Backend</h2>

<p>Let’s create a new file in the root directory named <code class="language-plaintext highlighter-rouge">api.py</code>. This is where we’ll be making a connection with Artic’s servers. To accomplish this, we’ll use the <code class="language-plaintext highlighter-rouge">requests</code> library:</p>

<p><code class="language-plaintext highlighter-rouge">api.py</code>:</p>
<pre><code class="python">
import requests
import os

web_api = 'https://api.artic.edu/api/v1/'
local_api = os.getcwd() + '/artic-api-data/json/'
url = "not specified"


def get(endpoint):

    return requests.get(url + endpoint)


def post(endpoint, query):

    # example_query = {
    #     'q': 'cats',
    #     'query': {
    #         'term': {
    #             'is_public_domain': True,
    #         },
    #     },
    # }

    return requests.post(url, json=query)



if __name__ == "__main__":
    url = web_api

    response = get('artworks')

    print(response.json())


</code></pre>

<p><code class="language-plaintext highlighter-rouge">requests</code> is not a built-in library, so you may have to install it: <code class="language-plaintext highlighter-rouge">pip install requests</code>. Once you run <code class="language-plaintext highlighter-rouge">api.py</code>, you should get a fat chunk of JSON in your output. And that’s pretty much the basic idea! We can check out the <a href="https://api.artic.edu/docs/#introduction">documentation</a> to learn more. Later on, we can add support for images stored locally.</p>

<h2 id="populating-our-gui-fields-with-api-data"><a id="populating-our-gui-fields-with-api-data"></a>Populating our GUI Fields with API Data</h2>
<p>Right now, our GUI dropdowns (artist, type, style) are empty. ARTIC’s search is powered by <a href="https://www.elastic.co/what-is/elasticsearch">ElasticSearch</a>, and we’ll need to formulate a query using ElasticSearch’s <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html">Query DSL</a> to get possible field values.</p>

<p>We’ll import <code class="language-plaintext highlighter-rouge">api.py</code> into <code class="language-plaintext highlighter-rouge">model.py</code> and send our query from there.</p>

<p><code class="language-plaintext highlighter-rouge">model.py</code>:</p>
<pre><code class="python">
+ import api
class Model():
    def __init__(self):
        self.file_management_model = FileManagementModel()
        self.artwork_criteria_model = ArtworkCriteriaModel()

    def populate_artists(self):
        api.get('query goes here')
    
    ...
</code></pre>

<h3 id="forming-a-connection"><a id="forming-a-connection"></a>Forming a Connection</h3>

<ul>
  <li>validating new values in model, updating view accordingly</li>
  <li>creating backend to communicate with artic</li>
  <li>populating comboboxes with artic options</li>
  <li>implementing file management options</li>
</ul>

<!-- I figure it's best to do basic UI validation in the view (e.g. only integers in the "Max Picture Count" field), and anything more complicated/important("Business Logic")c  -->

<!-- 
Alternatively, we could use [tkinter's validation](https://www.pythontutorial.net/tkinter/tkinter-validation/) in the view, but we'll do our validation in the model. I like the explanation given [here](https://stackoverflow.com/a/5607545) as to why it's a better idea. -->]]></content><author><name>Evan</name></author><category term="python" /><category term="web" /><summary type="html"><![CDATA[I’ve had the same desktop wallpaper for almost ten years. I’d like to change it up. I’d also like to feel like an intellectual. Luckily, the Art Institute of Chicago and their API can help me out.]]></summary></entry><entry><title type="html">Audio Plugins</title><link href="http://localhost:4000/2023/04/02/part-two.html" rel="alternate" type="text/html" title="Audio Plugins" /><published>2023-04-02T16:14:29-04:00</published><updated>2023-04-02T16:14:29-04:00</updated><id>http://localhost:4000/2023/04/02/part-two</id><content type="html" xml:base="http://localhost:4000/2023/04/02/part-two.html"><![CDATA[<h3 id="the-idea">The Idea</h3>
<p>We already have multiple example plugins from <a href="https://github.com/free-audio/clap">free-audio</a> and <a href="https://github.com/schwaaa/clap-imgui">schwaaa</a>, but there’s nothing like doing it yourself. I figured a simple arpeggiator with a rudimentary GUI would be a decent place to start. As usual, I’m not trying to make the wildest arpeggiator in the world here - I figure a time division and arp pattern parameter will suffice. Tryhard mode will be the next part in the series.</p>

<h3 id="creating-a-new-plugin">Creating a “New” Plugin</h3>
<p>If you’ve found your way here through my <a href="">last post</a> on audio plugins, you’ve likely already read <a href="https://github.com/schwaaa/clap-imgui#readme">schwaaa’s README</a>, but if you haven’t, I’d recommend doing so.</p>

<p>Anyway, this is the general plan for creating an arpeggiator:</p>

<blockquote>
  <p>The example code exports two very basic plugins, Volume/Pan and Tone Generator. You should be able to prototype basic plugins by editing (or adding) a src/plugin_impl_#.cpp file, which contains the actual audio plugin and UI implementation. The plugin descriptor and parameter definitions are at the top of the file, and plugin_impl__draw() contains the plugin-specific UI code.</p>

  <p>If you want to extend your plugin to add support for other CLAP extensions, you will need to add scaffolding code to src/plugin.cpp, similar to how the gui and parameter extensions are handled.</p>
</blockquote>

<p>We will likely have to add extensions like <code class="language-plaintext highlighter-rouge">note-ports.h</code> later on.</p>

<h3 id="adapting-schwaaas-volume-plugin-to-an-arp">Adapting schwaaa’s Volume Plugin to an Arp</h3>
<p>Almost all of the code we’ll be concerned with will be contained within <code class="language-plaintext highlighter-rouge">plugin_impl_2.cpp</code>, which is (as of right now) a copy of <code class="language-plaintext highlighter-rouge">plugin_impl_0.cpp</code>. Let’s step through, block by block, and make our changes.</p>

<p>«««&lt; HEAD</p>
<h4 id="info-and-paramters">Info and Paramters</h4>
<p>The first step is to</p>

<ol>
  <li>
    <h1 id="describe-our-plugin">Describe our plugin:</h1>
    <h4 id="info-and-dexcriptors">Info and Dexcriptors</h4>
    <p>The first step is to accurately describe our plugin, of course:</p>
  </li>
</ol>
<pre><code class="language-cpp">
&gt;&gt;&gt;&gt;&gt;&gt;&gt; 5129e8a5cef11c8c7916a0f4e455105568a47f0e

```cpp
static clap_plugin_descriptor _descriptor =
{
  CLAP_VERSION,
  "net.eldun.clap-arp",
  "CLAP Arp"
  "eldun",
  "eldun.github.io",
  "eldun.github.io",
  "eldun.github.io",
  "0.0.1",
  "Arpeggiator",
  _features
};
</code></pre>

<ol>
  <li>Describe our inputs</li>
</ol>]]></content><author><name>Evan</name></author><category term="c++" /><category term="music" /><category term="audio-plugins" /><summary type="html"><![CDATA[Now that we know what the deal is with CLAP, we can create a simple MIDI processor.]]></summary></entry><entry><title type="html">Gta Self Driving</title><link href="http://localhost:4000/2023/04/02/gta-self-driving.html" rel="alternate" type="text/html" title="Gta Self Driving" /><published>2023-04-02T16:14:29-04:00</published><updated>2023-04-02T16:14:29-04:00</updated><id>http://localhost:4000/2023/04/02/gta-self-driving</id><content type="html" xml:base="http://localhost:4000/2023/04/02/gta-self-driving.html"><![CDATA[<p>bored of working on (more like bored of thinking of working on) my SeeNatural app</p>

<p>been thinking about self-driving cars a lot</p>

<p>always loved gta 4’s driving model</p>

<p>real-time point-to-point driving. how would i…</p>
<ul>
  <li>get screen or game data?
    <ul>
      <li>360 emulator? OBS? Debug output?</li>
    </ul>
  </li>
  <li>process and interpret data?
    <ul>
      <li>convert to b&amp;w?</li>
    </ul>
  </li>
  <li>Send instructions to game?
    <ul>
      <li>pyAutoGui? vjoy?</li>
    </ul>
  </li>
  <li>emulator? virtual controller? What do i even send?</li>
  <li>improve driving?
    <ul>
      <li>what algorithms? machine learning? AI?</li>
    </ul>
  </li>
</ul>

<p>after some research, it seems like the Desktop Duplication API(https://docs.microsoft.com/en-gb/windows/win32/direct3ddxgi/desktop-dup-api) may be a good fit for my needs. btw, DXGI stands for “Direct X Graphics Infrastructure”</p>

<p>or opencv (open com)</p>

<p>OpenCV Object Detection in Games Python Tutorial (https://www.youtube.com/watch?v=KecMlLUuiE4 will likely be very useful resource)</p>]]></content><author><name></name></author><summary type="html"><![CDATA[bored of working on (more like bored of thinking of working on) my SeeNatural app been thinking about self-driving cars a lot always loved gta 4’s driving model real-time point-to-point driving. how would i… get screen or game data? 360 emulator? OBS? Debug output? process and interpret data? convert to b&amp;w? Send instructions to game? pyAutoGui? vjoy? emulator? virtual controller? What do i even send? improve driving? what algorithms? machine learning? AI? after some research, it seems like the Desktop Duplication API(https://docs.microsoft.com/en-gb/windows/win32/direct3ddxgi/desktop-dup-api) may be a good fit for my needs. btw, DXGI stands for “Direct X Graphics Infrastructure” or opencv (open com) OpenCV Object Detection in Games Python Tutorial (https://www.youtube.com/watch?v=KecMlLUuiE4 will likely be very useful resource)]]></summary></entry><entry><title type="html">Creating a 3D Engine in Java using LWJGL</title><link href="http://localhost:4000/2023/04/02/java-engine.html" rel="alternate" type="text/html" title="Creating a 3D Engine in Java using LWJGL" /><published>2023-04-02T16:14:29-04:00</published><updated>2023-04-02T16:14:29-04:00</updated><id>http://localhost:4000/2023/04/02/java-engine</id><content type="html" xml:base="http://localhost:4000/2023/04/02/java-engine.html"><![CDATA[<h2 id="what-is-lwjgl">What is LWJGL?</h2>
<blockquote>
  <p><a href="https://www.lwjgl.org/">Lightweight Java Game Library</a>(<a href="https://github.com/LWJGL/lwjgl3">GitHub</a>) is a Java library that enables cross-platform access to popular native APIs useful in the development of graphics (OpenGL/Vulkan), audio (OpenAL) and parallel computing (OpenCL) applications. This access is direct and high-performance, yet also wrapped in a type-safe and user-friendly layer, appropriate for the Java ecosystem.</p>
</blockquote>

<h2 id="setting-up-lwjgl">Setting up LWJGL</h2>
<p>I’ll be following LWJGL’s Installation Guide, which can be found <a href="https://github.com/LWJGL/lwjgl3-wiki/wiki/1.2.-Install">here</a>.</p>

<h3 id="downloading-lwjgl">Downloading LWJGL</h3>
<p>I’ll be using LWJGL’s <a href="https://www.lwjgl.org/customize">configurator</a> to download LWJGL with all default options selected <em>except</em> “Mode”:</p>

<p><span class="note">
Make sure you select the correct “natives” option selected. I’m creating this project on an aarch64(AKA arm64) chromebook, and x64 was checked by default.
</span></p>

<blockquote>
  <p>If you plan on using an IDE or need the actual .jar files, choose ZIP Bundle. If you are going to use maven or gradle, choose the respective option to generate a build script.</p>
</blockquote>

<blockquote>
  <p>Maven/Gradle is recommended during development. The zip bundle is recommended when creating a production build or installer for your application.</p>
</blockquote>

<p>I’ll be using Gradle because I found the documentation to be superior to Maven’s.</p>

<h3 id="setting-up-gradle">Setting up Gradle</h3>
<p>The Gradle installation instructions can be found <a href="https://docs.gradle.org/current/userguide/installation.html#installation">here</a>.</p>

<ul>
  <li>install <a href="https://sdkman.io/install">SDKMAN!</a> (Gradle is deployed and maintained <em>officially</em> on SDKMAN!)</li>
  <li><code class="language-plaintext highlighter-rouge">sdk install gradle</code></li>
  <li><code class="language-plaintext highlighter-rouge">gradle init</code></li>
</ul>

<p>This is what we end up with:</p>
<pre><code class="language-treeview">
JavaEngine/
├── app/
│   ├── bin/
│   │   ├── main/
│   │   │   └── javaengine/
│   │   │       └── App.class
│   │   └── test/
│   │       └── javaengine/
│   │           └── AppTest.class
│   ├── build/
│   │   ├── classes/
│   │   │   └── java/
│   │   │       ├── main/
│   │   │       │   └── javaengine/
│   │   │       │       └── App.class
│   │   │       └── test/
│   │   ├── generated/
│   │   │   └── sources/
│   │   │       ├── annotationProcessor/
│   │   │       │   └── java/
│   │   │       │       ├── main/
│   │   │       │       └── test/
│   │   │       └── headers/
│   │   │           └── java/
│   │   │               ├── main/
│   │   │               └── test/
│   │   └── tmp/
│   │       ├── compileJava/
│   │       │   └── previous-compilation-data.bin
│   │       └── compileTestJava/
│   ├── build.gradle
│   └── src/
│       ├── main/
│       │   ├── java/
│       │   │   └── javaengine/
│       │   │       └── App.java
│       │   └── resources/
│       └── test/
│           ├── java/
│           │   └── javaengine/
│           │       └── AppTest.java
│           └── resources/
├── gradle/
│   └── wrapper/
│       ├── gradle-wrapper.jar
│       └── gradle-wrapper.properties
├── gradlew*
├── gradlew.bat
├── README.md
└── settings.gradle
</code></pre>

<p>You can read more about the Gradle scaffolding generated by <code class="language-plaintext highlighter-rouge">gradle init</code> <a href="https://docs.gradle.org/current/samples/sample_building_java_applications.html#run_the_application">here</a>. Check <a href="https://docs.gradle.org/current/userguide/dependency_management.html">here</a> to learn more about Dependency management in Gradle.</p>

<p>Among other things, Gradle generates <code class="language-plaintext highlighter-rouge">JavaEngine/app/build.gradle</code>, which we’ll add to using the partial <code class="language-plaintext highlighter-rouge">build.gradle</code> file generated from LWJGL’s <a href="https://www.lwjgl.org/customize">configurator</a>:</p>

<pre><code class="language-gradle">
/*
 * This file was generated by the Gradle 'init' task.
 *
 * This generated file contains a sample Java application project to get you started.
 * For more details take a look at the 'Building Java &amp; JVM projects' chapter in the Gradle
 * User Manual available at https://docs.gradle.org/7.5.1/userguide/building_java_projects.html
 */

plugins {
    // Apply the application plugin to add support for building a CLI application in Java.
    id 'application'
}


project.ext.lwjglVersion = "3.3.1"
project.ext.lwjglNatives = "natives-linux-arm64"


repositories {
    // Use Maven Central for resolving dependencies.
    mavenCentral()
}

dependencies {
    // Use JUnit test framework.
    testImplementation 'junit:junit:4.13.2'

    // This dependency is used by the application.
    implementation 'com.google.guava:guava:31.0.1-jre'

    // LWJGL dependencies
    implementation platform("org.lwjgl:lwjgl-bom:$lwjglVersion")

	implementation "org.lwjgl:lwjgl"
	implementation "org.lwjgl:lwjgl-assimp"
	implementation "org.lwjgl:lwjgl-bgfx"
	implementation "org.lwjgl:lwjgl-cuda"
	implementation "org.lwjgl:lwjgl-egl"
	implementation "org.lwjgl:lwjgl-glfw"
	implementation "org.lwjgl:lwjgl-jawt"
	implementation "org.lwjgl:lwjgl-jemalloc"
	implementation "org.lwjgl:lwjgl-libdivide"
	implementation "org.lwjgl:lwjgl-llvm"
	implementation "org.lwjgl:lwjgl-lmdb"
	implementation "org.lwjgl:lwjgl-lz4"
	implementation "org.lwjgl:lwjgl-meow"
	implementation "org.lwjgl:lwjgl-meshoptimizer"
	implementation "org.lwjgl:lwjgl-nanovg"
	implementation "org.lwjgl:lwjgl-nfd"
	implementation "org.lwjgl:lwjgl-nuklear"
	implementation "org.lwjgl:lwjgl-odbc"
	implementation "org.lwjgl:lwjgl-openal"
	implementation "org.lwjgl:lwjgl-opencl"
	implementation "org.lwjgl:lwjgl-opengl"
	implementation "org.lwjgl:lwjgl-opengles"
	implementation "org.lwjgl:lwjgl-openxr"
	implementation "org.lwjgl:lwjgl-opus"
	implementation "org.lwjgl:lwjgl-par"
	implementation "org.lwjgl:lwjgl-remotery"
	implementation "org.lwjgl:lwjgl-rpmalloc"
	implementation "org.lwjgl:lwjgl-shaderc"
	implementation "org.lwjgl:lwjgl-spvc"
	implementation "org.lwjgl:lwjgl-stb"
	implementation "org.lwjgl:lwjgl-tinyexr"
	implementation "org.lwjgl:lwjgl-tinyfd"
	implementation "org.lwjgl:lwjgl-vma"
	implementation "org.lwjgl:lwjgl-vulkan"
	implementation "org.lwjgl:lwjgl-xxhash"
	implementation "org.lwjgl:lwjgl-yoga"
	implementation "org.lwjgl:lwjgl-zstd"
	runtimeOnly "org.lwjgl:lwjgl::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-assimp::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-bgfx::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-glfw::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-jemalloc::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-libdivide::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-llvm::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-lmdb::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-lz4::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-meow::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-meshoptimizer::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-nanovg::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-nfd::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-nuklear::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-openal::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-opengl::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-opengles::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-openxr::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-opus::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-par::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-remotery::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-rpmalloc::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-shaderc::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-spvc::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-stb::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-tinyexr::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-tinyfd::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-vma::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-xxhash::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-yoga::$lwjglNatives"
	runtimeOnly "org.lwjgl:lwjgl-zstd::$lwjglNatives"
}

application {
    // Define the main class for the application.
    mainClass = 'javaengine.App'
}

</code></pre>

<p>Thanks to the <code class="language-plaintext highlighter-rouge">application</code> plugin, we can run the application from the command line:</p>
<pre><code class="language-console">
./gradlew run

&gt; Task :app:run
Hello world!

BUILD SUCCESSFUL
2 actionable tasks: 2 executed
</code></pre>
<p>Read more about running our application (or any other Gradle questions you might have) <a href="https://docs.gradle.org/current/samples/sample_building_java_applications.html#run_the_application">here</a>.</p>

<h3 id="testing-our-lwjgl-environment">Testing our LWJGL Environment</h3>
<p>Just to make sure that LWJGL is configured correctly, we can attempt to execute some code that prints the current LWJGL version. Let’s replace the “Hello, World” code generated by Gradle in <code class="language-plaintext highlighter-rouge">app/src/main/java/javaengine/App.java</code> with the following:</p>

<pre><code class="language-java">

package javaengine;

import org.lwjgl.Version;

public class App { 

    public static void main(String[] args) {
        System.out.println("LWJGL Version " + Version.getVersion() + " is working.");

    }
}
</code></pre>

<pre><code class="language-console">
./gradlew run

LWJGL Version 3.3.1 build 7 is working.
</code></pre>

<h2 id="hello-window">Hello, Window!</h2>
<p>Now that we know everything is correctly set up, we can create a window!</p>

<p>Create a new class <code class="language-plaintext highlighter-rouge">HelloWorld.java</code> at <code class="language-plaintext highlighter-rouge">JavaEngine/app/src/main/java/javaengine</code> and paste the following:</p>

<pre><code class="language-java">
package javaengine;

import org.lwjgl.*;
import org.lwjgl.glfw.*;
import org.lwjgl.opengl.*;
import org.lwjgl.system.*;

import java.nio.*;

import static org.lwjgl.glfw.Callbacks.*;
import static org.lwjgl.glfw.GLFW.*;
import static org.lwjgl.opengl.GL11.*;
import static org.lwjgl.system.MemoryStack.*;
import static org.lwjgl.system.MemoryUtil.*;

public class HelloWorld {

	// The window handle
	private long window;

	public void run() {
		System.out.println("Hello LWJGL " + Version.getVersion() + "!");

		init();
		loop();

		// Free the window callbacks and destroy the window
		glfwFreeCallbacks(window);
		glfwDestroyWindow(window);

		// Terminate GLFW and free the error callback
		glfwTerminate();
		glfwSetErrorCallback(null).free();
	}

	private void init() {
		// Setup an error callback. The default implementation
		// will print the error message in System.err.
		GLFWErrorCallback.createPrint(System.err).set();

		// Initialize GLFW. Most GLFW functions will not work before doing this.
		if ( !glfwInit() )
			throw new IllegalStateException("Unable to initialize GLFW");

		// Configure GLFW
		glfwDefaultWindowHints(); // optional, the current window hints are already the default
		glfwWindowHint(GLFW_VISIBLE, GLFW_FALSE); // the window will stay hidden after creation
		glfwWindowHint(GLFW_RESIZABLE, GLFW_TRUE); // the window will be resizable

		// Create the window
		window = glfwCreateWindow(300, 300, "Hello World!", NULL, NULL);
		if ( window == NULL )
			throw new RuntimeException("Failed to create the GLFW window");

		// Setup a key callback. It will be called every time a key is pressed, repeated or released.
		glfwSetKeyCallback(window, (window, key, scancode, action, mods) -&gt; {
			if ( key == GLFW_KEY_ESCAPE &amp;&amp; action == GLFW_RELEASE )
				glfwSetWindowShouldClose(window, true); // We will detect this in the rendering loop
		});

		// Get the thread stack and push a new frame
		try ( MemoryStack stack = stackPush() ) {
			IntBuffer pWidth = stack.mallocInt(1); // int*
			IntBuffer pHeight = stack.mallocInt(1); // int*

			// Get the window size passed to glfwCreateWindow
			glfwGetWindowSize(window, pWidth, pHeight);

			// Get the resolution of the primary monitor
			GLFWVidMode vidmode = glfwGetVideoMode(glfwGetPrimaryMonitor());

			// Center the window
			glfwSetWindowPos(
				window,
				(vidmode.width() - pWidth.get(0)) / 2,
				(vidmode.height() - pHeight.get(0)) / 2
			);
		} // the stack frame is popped automatically

		// Make the OpenGL context current
		glfwMakeContextCurrent(window);
		// Enable v-sync
		glfwSwapInterval(1);

		// Make the window visible
		glfwShowWindow(window);
	}

	private void loop() {
		// This line is critical for LWJGL's interoperation with GLFW's
		// OpenGL context, or any context that is managed externally.
		// LWJGL detects the context that is current in the current thread,
		// creates the GLCapabilities instance and makes the OpenGL
		// bindings available for use.
		GL.createCapabilities();

		// Set the clear color
		glClearColor(1.0f, 0.0f, 0.0f, 0.0f);

		// Run the rendering loop until the user has attempted to close
		// the window or has pressed the ESCAPE key.
		while ( !glfwWindowShouldClose(window) ) {
			glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); // clear the framebuffer

			glfwSwapBuffers(window); // swap the color buffers

			// Poll for window events. The key callback above will only be
			// invoked during this call.
			glfwPollEvents();
		}
	}
}

</code></pre>

<p>Call <code class="language-plaintext highlighter-rouge">HelloWorld.run()</code> from our main method in <code class="language-plaintext highlighter-rouge">App.java</code>:</p>
<pre><code class="language-java">
package javaengine;

public class App {

	public static void main(String[] args) {
		new HelloWorld().run();
	}

}
</code></pre>]]></content><author><name>Evan</name></author><category term="graphics" /><category term="java" /><summary type="html"><![CDATA[What does it take to create an engine in Java?]]></summary></entry><entry><title type="html">Pi Hosting</title><link href="http://localhost:4000/2023/04/02/pi-hosting.html" rel="alternate" type="text/html" title="Pi Hosting" /><published>2023-04-02T16:14:29-04:00</published><updated>2023-04-02T16:14:29-04:00</updated><id>http://localhost:4000/2023/04/02/pi-hosting</id><content type="html" xml:base="http://localhost:4000/2023/04/02/pi-hosting.html"><![CDATA[<p>using this tutorial: https://fireship.io/lessons/host-website-raspberry-pi/</p>]]></content><author><name></name></author><summary type="html"><![CDATA[using this tutorial: https://fireship.io/lessons/host-website-raspberry-pi/]]></summary></entry><entry><title type="html">Learning OpenGL:</title><link href="http://localhost:4000/2023/04/02/post-boilerplate.html" rel="alternate" type="text/html" title="Learning OpenGL:" /><published>2023-04-02T16:14:29-04:00</published><updated>2023-04-02T16:14:29-04:00</updated><id>http://localhost:4000/2023/04/02/post-boilerplate</id><content type="html" xml:base="http://localhost:4000/2023/04/02/post-boilerplate.html"><![CDATA[<p><a id="continue-reading-point"></a>
blah blah blah
<!--end-excerpt--></p>

<hr />
<h2 id="contents">Contents</h2>

<ul class="table-of-contents">
    <li><a href="#what-is-opengl"></a></li>
</ul>

<hr />

<h2 id="what-is-opengl"><a id="what-is-opengl"></a>What is OpenGL?</h2>

<p>blah blah blah</p>

<hr />]]></content><author><name>Evan</name></author><category term="graphics" /><category term="opengl" /><summary type="html"><![CDATA[blah blah blah]]></summary></entry><entry><title type="html">See Natural</title><link href="http://localhost:4000/2023/04/02/see-natural.html" rel="alternate" type="text/html" title="See Natural" /><published>2023-04-02T16:14:29-04:00</published><updated>2023-04-02T16:14:29-04:00</updated><id>http://localhost:4000/2023/04/02/see-natural</id><content type="html" xml:base="http://localhost:4000/2023/04/02/see-natural.html"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Coding up an LV2 Synth Audio Plugin</title><link href="http://localhost:4000/2023/04/02/simple-lv2-synth.html" rel="alternate" type="text/html" title="Coding up an LV2 Synth Audio Plugin" /><published>2023-04-02T16:14:29-04:00</published><updated>2023-04-02T16:14:29-04:00</updated><id>http://localhost:4000/2023/04/02/simple-lv2-synth</id><content type="html" xml:base="http://localhost:4000/2023/04/02/simple-lv2-synth.html"><![CDATA[<h2 id="an-introduction">An introduction</h2>
<h3 id="what-is-an-audio-plugin">What is an Audio Plugin?</h3>
<p>An audio plugin is a piece of software (most often a virtual instrument or effect) that integrates into a <a href="https://en.wikipedia.org/wiki/Digital_audio_workstation">Digital Audio Workstation(DAW)</a> such as <a href="reaper.fm">Reaper</a> or <a href="ableton.com">Ableton Live</a>. There are quite a few different audio plugin formats - the most popular ones being:</p>
<ul>
  <li><a href="https://www.steinberg.net/technology/">VST3</a> - Steinberg’s closed-source solution turned open-source</li>
  <li><a href="https://developer.apple.com/documentation/audiotoolbox/audio_unit_v3_plug-ins">AUv3</a> - The iOS standard</li>
  <li><a href="https://www.avid.com/avid-plugins-by-category">AAX</a> - Avid/ProTools’ solution</li>
  <li>Standalone - As the name would imply, these types of plugins don’t require any host DAW. They can be launched and operated. Like NotePad.</li>
</ul>

<p>Many developers release their audio plugins under multiple formats - often by using licensed tools like <a href="https://juce.com/">JUCE</a>.</p>

<h3 id="what-is-lv2">What is LV2?</h3>
<p>From <a href="https://lv2plug.in/">lv2pkug.in</a>:</p>
<blockquote>
  <p>LV2 is an extensible open standard for audio plugins. LV2 has a simple core interface, which is accompanied by extensions that add more advanced functionality.</p>

  <p>Many types of plugins can be built with LV2, including audio effects, synthesizers, and control processors for modulation and automation. Extensions support more powerful features, such as:</p>

  <ul>
    <li>Platform-native UIs</li>
    <li>Network-transparent plugin control</li>
    <li>Portable and archivable persistent state</li>
    <li>Non-realtime tasks (like file loading) with sample-accurate export</li>
    <li>Semantic control with meaningful control designations and value units</li>
    <li>The LV2 specification and accompanying code is permissively licensed free software, with support for all major platforms.</li>
  </ul>
</blockquote>

<h3 id="why-choose-lv2">Why Choose LV2?</h3>
<p>I originally was going to create a VST3 synth(<a href="https://github.com/eldun/eldun.github.io/blob/source/_drafts/simple-synth.md">I even started a blog post :c</a>), but found Steinberg’s <a href="https://steinbergmedia.github.io/vst3_dev_portal/pages/">documentation</a> to be lacking and poorly organized - especially for the Linux platform, which is where I’m doing most of my coding as of late. LV2, on the other hand is platform-agnostic, <a href="https://lv2plug.in/pages/developing.html">well-documented</a>, and open-source from the start.</p>

<p><a href="https://lv2plug.in/pages/why-lv2.html">Here’s a list of reasons to use LV2 straight from the source</a>.</p>

<h3 id="what-does-an-audio-plugin-look-like">What Does an Audio Plugin Look Like?</h3>
<p>There are thousands upon thousands of plugins out there - ranging from minimalist retro synths and complex rhythm sequencers to Karplus-Strong string modelers and destructive bit-crushers. Here are some of my favorites:</p>

<p><a href="vital.audio">Vital</a>
<img src="/assets/images/blog-images/simple-synth/vital.jpg" alt="Vital" />
<a href="https://asb2m10.github.io/dexed/">Dexed</a>
<img src="/assets/images/blog-images/simple-synth/dexed.png" alt="Dexed" />
<img src="/assets/images/blog-images/simple-synth/valhalla-delay.webp" alt="Valhalla Freq Echo" />
<a href="https://valhalladsp.com/shop/delay/valhalla-freq-echo/">Valhalla Freq Echo</a>
<img src="/assets/images/blog-images/simple-synth/blue-arp.png" alt="BlueARP Arpeggiator" />
<a href="https://omg-instruments.com/wp/?page_id=63">BlueARP Arpeggiator</a></p>

<h2 id="setting-up-lv2">Setting Up LV2</h2>

<h3 id="resources">Resources</h3>
<p>LV2 doesn’t have an official guide, but comes with a few well-documented example plugins. There’s also a “<a href="https://lv2plug.in/book/#_introduction">book</a>” that walks through the included examples.</p>

<p>A short list of development topics can be read about <a href="https://lv2plug.in/pages/developing.html">here</a>.</p>

<h3 id="downloading-lv2">Downloading LV2</h3>
<p>At the time of this writing, LV2 can be downloaded from <a href="https://lv2plug.in/">LV2’s homepage</a>. There’s also a <a href="https://gitlab.com/lv2/lv2">gitlab repository</a>.</p>

<h3 id="installing-lv2">Installing LV2</h3>
<p><a href="https://gitlab.com/lv2/lv2/-/blob/master/INSTALL.md">Installation instructions</a> are included in the LV2 download.</p>

<h4 id="installing-dependency-meson">Installing Dependency Meson</h4>
<ul>
  <li><a href="https://mesonbuild.com/index.html">Meson</a> is LV2’s chosen build system.</li>
  <li><a href="https://mesonbuild.com/Getting-meson.html">Installing Meson</a>: <code class="language-plaintext highlighter-rouge">sudo apt install meson</code>.</li>
  <li><a href="https://mesonbuild.com/Quick-guide.html">Getting Started with Meson</a>.</li>
</ul>

<h4 id="configuration">Configuration</h4>
<blockquote>
  <p>The build is configured with the setup command, which creates a new build directory with the given name:</p>

  <p><code class="language-plaintext highlighter-rouge">meson setup build</code></p>
</blockquote>

<p>(Just run <code class="language-plaintext highlighter-rouge">meson setup build</code> from the LV2 root directory)</p>

<p>From within the newly created <code class="language-plaintext highlighter-rouge">build</code> directory, you can:</p>
<ul>
  <li><a href="https://gitlab.com/lv2/lv2/-/blob/master/INSTALL.md#building"><code class="language-plaintext highlighter-rouge">meson compile</code></a></li>
  <li><a href="https://gitlab.com/lv2/lv2/-/blob/master/INSTALL.md#building"><code class="language-plaintext highlighter-rouge">meson test</code></a></li>
  <li><a href="https://gitlab.com/lv2/lv2/-/blob/master/INSTALL.md#installation"><code class="language-plaintext highlighter-rouge">meson install</code></a></li>
</ul>

<blockquote>
  <p>You may need to acquire root permissions to install to a system-wide prefix. For packaging, the installation may be staged to a directory using the DESTDIR environment variable or the –destdir option:</p>

  <pre><code class="language-console">
DESTDIR=/tmp/mypackage/ meson install

meson install --destdir=/tmp/mypackage/
</code></pre>
</blockquote>

<blockquote>
  <p>By default, on UNIX-like systems, everything is installed within the <code>prefix</code>,
and LV2 bundles are installed in the “lv2” subdirectory of the <code>libdir</code>.  On
other systems, bundles are installed by default to the standard location for
plugins on the system. The bundle installation directory can be overridden
with the <code>lv2dir</code> option.
The specification bundles are run-time dependencies of LV2 applications.
Programs expect their data to be available somewhere in <code class="language-plaintext highlighter-rouge">LV2_PATH</code>.  See
<a href="http://lv2plug.in/pages/filesystem-hierarchy-standard.html">http://lv2plug.in/pages/filesystem-hierarchy-standard.html</a> for details on the
standard installation paths.</p>
</blockquote>

<blockquote>
  <p>Configuration options(such as <code class="language-plaintext highlighter-rouge">lv2dir</code>) can be inspected with the <code class="language-plaintext highlighter-rouge">configure</code> command from within the <code class="language-plaintext highlighter-rouge">build</code> directory:</p>

  <pre><code class="language-console">
cd build
meson configure
</code></pre>
</blockquote>

<blockquote>
  <p>Options can be set by passing C-style “define” options to configure:</p>

  <p><code class="language-plaintext highlighter-rouge">meson configure -Dc_args="-march=native" -Dprefix="/opt/mypackage/"</code></p>

  <p>Note that some options, such as strict and werror are for
developer/maintainer use only.  Please don’t file issues about anything that
happens when they are enabled.</p>
</blockquote>]]></content><author><name>Evan</name></author><category term="audio" /><category term="music" /><category term="c++" /><summary type="html"><![CDATA[Are synths as fun to code as they are to play?]]></summary></entry><entry><title type="html">Writing a Simple Synth VST Plug-in</title><link href="http://localhost:4000/2023/04/02/simple-synth.html" rel="alternate" type="text/html" title="Writing a Simple Synth VST Plug-in" /><published>2023-04-02T16:14:29-04:00</published><updated>2023-04-02T16:14:29-04:00</updated><id>http://localhost:4000/2023/04/02/simple-synth</id><content type="html" xml:base="http://localhost:4000/2023/04/02/simple-synth.html"><![CDATA[<h2 id="what-is-vst">What is VST?</h2>
<p>VST stands for “Virtual Studio Technology” - it’s an audio plug-in software interface that integrates virtual instruments and effects into digital audio workstations such as <a href="reaper.fm">Reaper</a> or <a href="ableton.com">Ableton Live</a>. If you’d like to learn more, you can check out <a href="https://en.wikipedia.org/wiki/Virtual_Studio_Technology">Wikipedia’s VST page</a>.</p>

<h2 id="what-does-a-vst-plug-in-look-like">What Does a VST Plug-in Look Like?</h2>
<p>There are thousands upon thousands of VSTs out there - ranging from minimalist retro synths and complex rhythm sequencers to Karplus-Strong string modelers and destructive bit-crushers. Here are some of my favorites:</p>

<p><span class="row">
<span class="captioned-image">
<a href="vital.audio">Vital</a>
<img src="/assets/images/blog-images/simple-synth/vital.jpg" alt="Vital" />
</span>
<span class="captioned-image">
<a href="https://asb2m10.github.io/dexed/">Dexed</a>
<img src="/assets/images/blog-images/simple-synth/dexed.png" alt="Dexed" />
</span>
</span></p>

<p><span class="row">
<span class="captioned-image">
<img src="/assets/images/blog-images/simple-synth/valhalla-delay.webp" alt="Valhalla Freq Echo" />
<a href="https://valhalladsp.com/shop/delay/valhalla-freq-echo/">Valhalla Freq Echo</a>
</span>
<span class="captioned-image">
<img src="/assets/images/blog-images/simple-synth/blue-arp.png" alt="BlueARP Arpeggiator" />
<a href="https://omg-instruments.com/wp/?page_id=63">BlueARP Arpeggiator</a> 
</span>
</span></p>

<h2 id="starting-small">Starting Small</h2>
<p>I’ve done a small amount of coding that involved audio before, but that was for Android - I know almost nothing about creating VSTs. Thankfully, there’s a lot of literature out there - I’ll be following <a href="http://www.martin-finke.de/blog/tags/making_audio_plugins.html">this guide</a> by Martin Finke. The first step on the journey will be creating a simple distortion plug-in (rock and roll!) to get familiar with the tools and concepts involved in VST creation:</p>
<blockquote>
  <p>We will use C++ and the WDL-OL library. It is based on Cockos WDL (pronounced whittle). It basically does a lot of work for us, most importantly:</p>
  <ul>
    <li>Ready-made Xcode / Visual Studio Projects</li>
    <li>Create VST, AudioUnit, VST3 and RTAS formats from one codebase: Just choose the plugin format and click run!</li>
    <li>Create 32/64-Bit executables</li>
    <li>Make your plugin run as a standalone Win/Mac application</li>
    <li>Most GUI controls used in audio plugins</li>
  </ul>
</blockquote>

<p>We don’t have to worry about the different VST formats thanks to IPlug - an abstraction layer that’s part of WDL.</p>

<h2 id="installing-dependencies">Installing Dependencies</h2>
<p>The first order of business is to download the VST3 SDK from <a href="https://www.steinberg.net/developers/">Steinberg</a>. Unfortunately, the guide I’m following isn’t tailored for Linux users - I’ll have to do some digging as to actually make use of it. So far, the most promising steps I’ve found are <a href="https://steinbergmedia.github.io/vst3_dev_portal/pages/Getting+Started/How+to+setup+my+system.html#for-linux">here (system setup)</a> and <a href="https://steinbergmedia.github.io/vst3_dev_portal/pages/Tutorials/Building+the+examples+included+in+the+SDK+Linux.html#part-2-building-the-examples-on-linux">here (building the example)</a>. Note that to install dependencies, you can run the script “setup_linux_packages_for_vst3sdk.sh” included in the VST3_SDK/tools folder.</p>

<h2 id="building-the-included-examples">Building the Included Examples</h2>
<p>Now we have to install <a href="https://cmake.org/install/">cmake</a> to control the compilation process. I ran into issues on my Chromebook running executing the bootstrap file - extracting the cmake tarball to (and installing from) /home instead of /mnt solved my issues.</p>

<p>A helpful tutorial on CMake can be found <a href="https://cmake.org/cmake/help/latest/guide/tutorial/index.html">here</a></p>

<p>The next step is to construct our build folder with CMake, which will include some example VSTs.
&lt;/code&gt;&lt;/pre&gt;
mkdir build
cd build</p>

<p>cmake ../VST_SDK/vst3sdk/
cmake –build .
&lt;/code&gt;&lt;/pre&gt;
The resulting <code class="language-plaintext highlighter-rouge">build/VST3/Debug</code> folder is full of example VSTs:
&lt;/code&gt;&lt;/pre&gt;
adelay.vst3                helloworld.vst3            multiple_programchanges.vst3  prefetchable.vst3
again-sampleaccurate.vst3  helloworldWithVSTGUI.vst3  noteexpressionsynth.vst3      programchange.vst3
againsimple.vst3           hostchecker.vst3           noteexpressiontext.vst3       syncdelay.vst3
again.vst3                 legacymidiccout.vst3       panner.vst3
channelcontext.vst3        mda-vst3.vst3              pitchnames.vst3
&lt;/code&gt;&lt;/pre&gt;
Now we need a VST host - I already have Reaper installed, so that’s what I’ll be using. After setting up the path to our new VSTs in Reaper, we can load some up:</p>

<p><img src="/assets/images/blog-images/simple-synth/vst-examples.png" alt="Example Steinberg VST Plug-ins loaded up in Reaper" /></p>

<h2 id="creating-a-new-project">Creating a New Project</h2>
<h3 id="from-the-project-generator">From the Project Generator</h3>
<p>Steinberg recommends using the open source <a href="https://github.com/steinbergmedia/vst3projectgenerator">VST Project Generator</a> for generating new projects:
<img src="/assets/images/blog-images/simple-synth/project-generator.png" alt="VST Project Generator" /> <br />
However, as far as I can tell, the GUI only works on MacOS/Windows. There is a script within the repo you can run to generate a project as well, but there would still be some annoying <a href="https://steinbergmedia.github.io/vst3_dev_portal/pages/Tutorials/Use+VSTGUI+to+design+a+UI.html#part-1-preparation">Manual editing</a> you’d have to do. And after you do that, I don’t find the documentation to be super clear. Which brings me to the better-explained alternative…</p>

<h3 id="from-the-helloworld-template">From the Helloworld Template</h3>
<p>Follwing the article <a href="https://steinbergmedia.github.io/vst3_dev_portal/pages/Tutorials/Creating+a+plug-in+from+the+Helloworld+template.html">here</a></p>

<h2 id="using-vstgui">Using VSTGUI</h2>
<h3 id="setup">Setup</h3>
<p>(Following the article <a href="https://steinbergmedia.github.io/vst3_dev_portal/pages/Tutorials/Index.html#use-vstgui-to-design-a-user-interface">here</a>)</p>

<blockquote>
  <p>If you have created your project with the VST 3 Project Generator and check the “Use VSTGUI” (I didn’t - as far as I can tell it’s only for Mac/Windows) you can directly jump to Part 2 of this tutorial.</p>
</blockquote>

<p>Since there’s no GUI for linux, I had to do some digging. Cloning the VST 3 Project Generator from <a href="https://github.com/steinbergmedia/vst3projectgenerator">Github</a>, I found a script that I could run to generate a project at vst3projectgenerator/script/GenerateVST3Plugin.cmake. Here’s the readme:</p>

<blockquote>
  <p><strong>Usage</strong></p>

  <p>Execute on command line:</p>

  <pre><code class="language-console">&gt; $ cmake -P GenerateVST3Plugin.cmake
</code></pre>

  <p>The script will output all variables and its current values. In order to adapt variables, edit</p>

  <pre><code class="language-console">&gt; vst3plugingenerator/cmake/modules/SMTG_VendorSpecifics.cmake
</code></pre>

  <p>file to your needs.</p>

  <p>After the script has finished you will find a</p>

  <pre><code class="language-console">&gt; vst3plugingenerator/myplugin
</code></pre>

  <p>folder in the directory the script was executed in.</p>
</blockquote>

<p>And here’s my <code class="language-plaintext highlighter-rouge">vst3plugingenerator/cmake/modules/SMTG_VendorSpecifics.cmake</code>:
cmake_minimum_required(VERSION 3.14.0)</p>

<p>string(TIMESTAMP SMTG_CURRENT_YEAR %Y)</p>

<p>set(SMTG_VENDOR_NAME “eldun”)
set(SMTG_VENDOR_HOMEPAGE “eldun.github.io”)
set(SMTG_VENDOR_EMAIL “evan@eldun.net”)
set(SMTG_PLUGIN_NAME “SimpleSynth”)
set(SMTG_PLUGIN_IDENTIFIER “com.eldun.simplesynth.vst3”)</p>

<h1 id="source-code-specifics">Source code specifics</h1>
<p>set(SMTG_VENDOR_NAMESPACE “eldun”)
set(SMTG_PLUGIN_CLASS_NAME “SimpleSynth”)
set(SMTG_PREFIX_FOR_FILENAMES “simplesynth”)
set(SMTG_PLUGIN_BUNDLE_NAME “SimpleSynth”)
set(SMTG_PLUGIN_CATEGORY “Synthesizer”)</p>
<h1 id="setsmtg_macos_deployment_target-1012">set(SMTG_MACOS_DEPLOYMENT_TARGET “10.12”)</h1>

<h1 id="replace-by-command-line-arguments">Replace by command line arguments</h1>
<p>if(SMTG_VENDOR_NAME_CLI)
    string(REPLACE “"” “” SMTG_VENDOR_NAME ${SMTG_VENDOR_NAME_CLI})
endif()
if(SMTG_VENDOR_HOMEPAGE_CLI)
    string(REPLACE “"” “” SMTG_VENDOR_HOMEPAGE ${SMTG_VENDOR_HOMEPAGE_CLI})
endif()
if(SMTG_VENDOR_EMAIL_CLI)
    string(REPLACE “"” “” SMTG_VENDOR_EMAIL ${SMTG_VENDOR_EMAIL_CLI})
endif()
if(SMTG_PLUGIN_NAME_CLI)
    string(REPLACE “"” “” SMTG_PLUGIN_NAME ${SMTG_PLUGIN_NAME_CLI})
endif()
if(SMTG_PREFIX_FOR_FILENAMES_CLI)
Now we have to install <a href="https://cmake.org/install/">cmake</a> to control the compilation process. I ran into issues on my Chromebook running executing the bootstrap file - extracting the cmake tarball to (and installing from) /home instead of /mnt solved my issues.</p>

<p>A helpful tutorial on CMake can be found <a href="https://cmake.org/cmake/help/latest/guide/tutorial/index.html">here</a></p>

<p>The next step is to construct our build folder with CMake, which will include some example VSTs.
&lt;/code&gt;&lt;/pre&gt;
mkdir build
cd build</p>

<p>cmake ../VST_SDK/vst3sdk/
cmake –build .
&lt;/code&gt;&lt;/pre&gt;
The resulting <code class="language-plaintext highlighter-rouge">build/VST3/Debug</code> folder is full of example VSTs:
&lt;/code&gt;&lt;/pre&gt;
adelay.vst3                helloworld.vst3            multiple_programchanges.vst3  prefetchable.vst3
again-sampleaccurate.vst3  helloworldWithVSTGUI.vst3  noteexpressionsynth.vst3      programchange.vst3
againsimple.vst3           hostchecker.vst3           noteexpressiontext.vst3       syncdelay.vst3
again.vst3                 legacymidiccout.vst3       panner.vst3
channelcontext.vst3        mda-vst3.vst3              pitchnames.vst3
&lt;/code&gt;&lt;/pre&gt;
Now we need a VST host - I already have Reaper installed, so that’s what I’ll be using. After setting up the path to our new VSTs in Reaper, we can load some up:</p>

<p><img src="/assets/images/blog-images/simple-synth/vst-examples.png" alt="Example Steinberg VST Plug-ins loaded up in Reaper" /></p>

<h2 id="using-vstgui-1">Using VSTGUI</h2>
<h3 id="setup-1">Setup</h3>
<p>(Following the article <a href="https://steinbergmedia.github.io/vst3_dev_portal/pages/Tutorials/Index.html#use-vstgui-to-design-a-user-interface">here</a>)</p>

<blockquote>
  <p>If you have created your project with the VST 3 Project Generator and check the “Use VSTGUI” (I didn’t - as far as I can tell it’s only for Mac/Windows) you can directly jump to Part 2 of this tutorial.</p>
</blockquote>

<p>Since there’s no GUI for linux, I had to do some digging. Cloning the VST 3 Project Generator from <a href="https://github.com/steinbergmedia/vst3projectgenerator">Github</a>, I found a script that I could run to generate a project at vst3projectgenerator/script/GenerateVST3Plugin.cmake. Here’s the readme:</p>

<blockquote>
  <p><strong>Usage</strong></p>

  <p>Execute on command line:</p>

  <pre><code class="language-console">&gt; $ cmake -P GenerateVST3Plugin.cmake
</code></pre>

  <p>The script will output all variables and its current values. In order to adapt variables, edit</p>

  <pre><code class="language-console">&gt; vst3plugingenerator/cmake/modules/SMTG_VendorSpecifics.cmake
</code></pre>

  <p>file to your needs.</p>

  <p>After the script has finished you will find a</p>

  <pre><code class="language-console">&gt; vst3plugingenerator/myplugin
</code></pre>

  <p>folder in the directory the script was executed in.</p>
</blockquote>

<p>And here’s my <code class="language-plaintext highlighter-rouge">vst3plugingenerator/cmake/modules/SMTG_VendorSpecifics.cmake</code>:
cmake_minimum_required(VERSION 3.14.0)</p>

<p>string(TIMESTAMP SMTG_CURRENT_YEAR %Y)</p>

<p>set(SMTG_VENDOR_NAME “eldun”)
set(SMTG_VENDOR_HOMEPAGE “eldun.github.io”)
set(SMTG_VENDOR_EMAIL “evan@eldun.net”)
set(SMTG_PLUGIN_NAME “SimpleSynth”)
set(SMTG_PLUGIN_IDENTIFIER “com.eldun.simplesynth.vst3”)</p>

<h1 id="source-code-specifics-1">Source code specifics</h1>
<p>set(SMTG_VENDOR_NAMESPACE “eldun”)
set(SMTG_PLUGIN_CLASS_NAME “SimpleSynth”)
set(SMTG_PREFIX_FOR_FILENAMES “simplesynth”)
set(SMTG_PLUGIN_BUNDLE_NAME “SimpleSynth”)
set(SMTG_PLUGIN_CATEGORY “Synthesizer”)</p>
<h1 id="setsmtg_macos_deployment_target-1012-1">set(SMTG_MACOS_DEPLOYMENT_TARGET “10.12”)</h1>

<h1 id="replace-by-command-line-arguments-1">Replace by command line arguments</h1>
<p>if(SMTG_VENDOR_NAME_CLI)
    string(REPLACE “"” “” SMTG_VENDOR_NAME ${SMTG_VENDOR_NAME_CLI})
endif()
if(SMTG_VENDOR_HOMEPAGE_CLI)
    string(REPLACE “"” “” SMTG_VENDOR_HOMEPAGE ${SMTG_VENDOR_HOMEPAGE_CLI})
endif()
    string(REPLACE “"” “” SMTG_PLUGIN_IDENTIFIER ${SMTG_PLUGIN_IDENTIFIER_CLI})
endif()
if(SMTG_PLUGIN_CLASS_NAME_CLI)
    string(REPLACE “"” “” SMTG_PLUGIN_CLASS_NAME ${SMTG_PLUGIN_CLASS_NAME_CLI})
endif()
if(SMTG_VENDOR_NAMESPACE_CLI)
    string(REPLACE “"” “” SMTG_VENDOR_NAMESPACE ${SMTG_VENDOR_NAMESPACE_CLI})
endif()
if(SMTG_PLUGIN_CATEGORY_CLI)
    string(REPLACE “"” “” SMTG_PLUGIN_CATEGORY ${SMTG_PLUGIN_CATEGORY_CLI})
endif()
if(SMTG_PLUGIN_BUNDLE_NAME_CLI)
    string(REPLACE “"” “” SMTG_PLUGIN_BUNDLE_NAME ${SMTG_PLUGIN_BUNDLE_NAME_CLI})
endif()
if(SMTG_CMAKE_PROJECT_NAME_CLI)
    string(REPLACE “"” “” SMTG_CMAKE_PROJECT_NAME ${SMTG_CMAKE_PROJECT_NAME_CLI})
else()
    set(SMTG_CMAKE_PROJECT_NAME ${SMTG_PLUGIN_BUNDLE_NAME})
endif()
if(SMTG_MACOS_DEPLOYMENT_TARGET_CLI)
    string(REPLACE “"” “” SMTG_MACOS_DEPLOYMENT_TARGET ${SMTG_MACOS_DEPLOYMENT_TARGET_CLI})
endif()</p>

<p>set(SMTG_SOURCE_COPYRIGHT_HEADER “Copyright(c) ${SMTG_CURRENT_YEAR} ${SMTG_VENDOR_NAME}.”)</p>

<p>function(smtg_print_vendor_specifics)
    message(STATUS “SMTG_VENDOR_NAME            : ${SMTG_VENDOR_NAME}”)
    message(STATUS “SMTG_VENDOR_HOMEPAGE        : ${SMTG_VENDOR_HOMEPAGE}”)
    message(STATUS “SMTG_VENDOR_EMAIL           : ${SMTG_VENDOR_EMAIL}”)
    message(STATUS “SMTG_SOURCE_COPYRIGHT_HEADER: ${SMTG_SOURCE_COPYRIGHT_HEADER}”)
    message(STATUS “SMTG_PLUGIN_NAME            : ${SMTG_PLUGIN_NAME}”)
    message(STATUS “SMTG_PREFIX_FOR_FILENAMES   : e.g. ${SMTG_PREFIX_FOR_FILENAMES}controller.h”)
    message(STATUS “SMTG_PLUGIN_IDENTIFIER      : ${SMTG_PLUGIN_IDENTIFIER}, used e.g. in Info.plist”)
    message(STATUS “SMTG_PLUGIN_BUNDLE_NAME     : ${SMTG_PLUGIN_BUNDLE_NAME}”)
    message(“”)
    message(STATUS “SMTG_CMAKE_PROJECT_NAME     : e.g. ${SMTG_CMAKE_PROJECT_NAME} will output ${SMTG_CMAKE_PROJECT_NAME}.vst3”)
    message(STATUS “SMTG_VENDOR_NAMESPACE       : e.g. namespace ${SMTG_VENDOR_NAMESPACE} {…}”)
    message(STATUS “SMTG_PLUGIN_CLASS_NAME      : e.g. class ${SMTG_PLUGIN_CLASS_NAME}Processor : public AudioEffect {…}”)
    message(STATUS “SMTG_PLUGIN_CATEGORY        : ${SMTG_PLUGIN_CATEGORY}”)
    message(STATUS “SMTG_MACOS_DEPLOYMENT_TARGET: ${SMTG_MACOS_DEPLOYMENT_TARGET}”)
    message(“”)
endfunction(smtg_print_vendor_specifics)</p>

<blockquote>
  <p>Before using the inline UI editor, you must make sure that you use the Steinberg::Vst::EditController class as a base of your own edit controller and that you have used the Steinberg::Vst::Parameter class or any subclass of it for your parameters. Otherwise the inline UI editor won’t work properly.</p>

  <p>Next you have to add vstgui to your project. For cmake users, you can just add the vstgui_support library to your target:</p>

  <p>target_link_libraries(${target} PRIVATE vstgui_support)</p>
</blockquote>

<p>I’m not yet an expert with Cmake, so I looked at the included plugin example CMakeLists.txt at /VST_SDK/my_plugins/helloworld_with_VSTGUI/ for an example:</p>

<p>&lt;/code&gt;&lt;/pre&gt;</p>

<p>if(NOT SMTG_ADD_VSTGUI)
    return()
endif()</p>

<p>cmake_minimum_required(VERSION 3.15.0)</p>

<p>project(smtg-vst3-helloworldWithVSTGUI
    VERSION ${vstsdk_VERSION}.0
    DESCRIPTION “Steinberg VST 3 helloworldWithVSTGUI example”
)</p>

<p>smtg_add_vst3plugin(helloworldWithVSTGUI   <br />
    include/plugcontroller.h
    include/plugids.h
    include/plugprocessor.h
    include/version.h
    source/plugfactory.cpp
    source/plugcontroller.cpp
    source/plugprocessor.cpp
)</p>

<p>if(SMTG_MAC)
    smtg_target_set_bundle(helloworldWithVSTGUI
        BUNDLE_IDENTIFIER “com.steinberg.helloworldWithVSTGUI”
        COMPANY_NAME “Steinberg Media Technologies”
)
elseif(SMTG_WIN)
    target_sources(helloworldWithVSTGUI
        PRIVATE 
            resource/info.rc
)
endif()</p>

<p>configure_file(${SDK_ROOT}/cmake/templates/projectversion.h.in projectversion.h)</p>

<p>target_include_directories(helloworldWithVSTGUI PUBLIC
    “${PROJECT_BINARY_DIR}”
)</p>

<p>target_link_libraries(helloworldWithVSTGUI
    PRIVATE
        sdk
        vstgui_support
)</p>

<p>smtg_target_add_plugin_resources(helloworldWithVSTGUI
    RESOURCES
        resource/plug.uidesc
        resource/background.png
        resource/animation_knob.png
        resource/onoff_button.png
        resource/background_2x.png
        resource/animation_knob_2x.png
        resource/onoff_button_2x.png
        resource/background_3x.png
        resource/animation_knob_3x.png
        resource/onoff_button_3x.png
)</p>

<p>smtg_target_add_plugin_snapshots(helloworldWithVSTGUI
    RESOURCES
        resource/41E3A6A2C1991743A64945DC3FB7D51D_snapshot.png
        resource/41E3A6A2C1991743A64945DC3FB7D51D_snapshot_2.0x.png
)
&lt;/code&gt;&lt;/pre&gt;</p>

<p>This only looks slightly different from the script-generated <code class="language-plaintext highlighter-rouge">CMakeLists.txt</code> for <code class="language-plaintext highlighter-rouge">VST_SDK/my_plugins/SimpleSynth/CMakeLists.txt</code>:
&lt;/code&gt;&lt;/pre&gt;
cmake_minimum_required(VERSION 3.14.0)
set(CMAKE_OSX_DEPLOYMENT_TARGET  CACHE STRING “”)
The <a href="https://steinbergmedia.github.io/vst3_dev_portal/pages/Tutorials/Using+cmake+for+building+plug-ins.html#available-smtg-cmake-options">SMTG option</a> “SMTG_ADD_VSTGUI” is on by default.</p>

<p>Next, you have to</p>

<blockquote>
  <p>alter your project settings to add a preprocessor definition to your debug build:</p>

  <p>VSTGUI_LIVE_EDITING=1
With cmake, this would look like this:</p>

  <p>target_compile_definitions(${target} PUBLIC$&lt;$<CONFIG:Debug>:VSTGUI_LIVE_EDITING=1&gt;)</CONFIG:Debug></p>
</blockquote>

<p>I threw this line in at the end of the “VST_GUI Wanted” section:</p>

<p>&lt;/code&gt;&lt;/pre&gt;
target_compile_definitions(SimpleSynth 
        PUBLIC
            $&lt;$<CONFIG:Debug>:VSTGUI_LIVE_EDITING=1&gt;)
&lt;/code&gt;&lt;/pre&gt;</CONFIG:Debug></p>

<blockquote>
  <p>Finally, you have to modify your edit controller class to overwrite the createView() method</p>
</blockquote>

<p>As far as I could tell, the method they show in <a href="https://steinbergmedia.github.io/vst3_dev_portal/pages/Tutorials/Use+VSTGUI+to+design+a+UI.html">the article</a> and the one in <code class="language-plaintext highlighter-rouge">vst3sdk/vstgui4/vstgui/plugin-bindings/vst3editor.cpp</code> are identical.</p>

<h3 id="using-the-vstgui-ui-editor">Using the VSTGUI UI Editor</h3>
<p>Running the plugin in our DAW, we can see there’s a popup to use the visual editor:
<img src="/assets/images/blog-images/simple-synth/ui-editor-popup.png" alt="UI Editor Popup Option" />
<img src="/assets/images/blog-images/simple-synth/ui-editor.png" alt="UI Editor" /></p>

<p>Note that we have to save any changes within the editor (which would be the uidesc file), and we have to build our project after any changes to the uidesc file to see our changes.</p>]]></content><author><name>Evan</name></author><category term="synthesis" /><category term="music" /><category term="c++" /><summary type="html"><![CDATA[Are synths as fun to write as they are to play with?]]></summary></entry></feed>